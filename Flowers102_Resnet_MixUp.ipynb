{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ys1Pd_f7-Crk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Flowers102\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ELsdngo-ITz",
    "outputId": "fd980064-693c-42e1-f134-d9863067ba2a"
   },
   "outputs": [],
   "source": [
    "# Load the Flowers102 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Download the dataset (training split)\n",
    "train_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='train',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")\n",
    "\n",
    "# Download the dataset (validation split)\n",
    "val_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='val',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")\n",
    "\n",
    "# Download the dataset (test split)\n",
    "test_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='test',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2uvGsdkC-ajv"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MixUp function\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MixUp data loader\n",
    "def mixup_loader(dataloader, alpha=1.0):\n",
    "    for data, target in dataloader:\n",
    "        data, target_a, target_b, lam = mixup_data(data, target, alpha)\n",
    "        yield data, target_a, target_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDiTpYS7-L9p",
    "outputId": "22e7f781-a506-442d-9974-79e06c2de0a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define the ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc.requires_grad = True\n",
    "\n",
    "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
    "model.fc = nn.Linear(model.fc.in_features, 102)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yi5L1Lmd_dQX",
    "outputId": "96386491-b183-4f46-c3bd-ce87f48a1400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.6821287125349045\n",
      "Training Accuracy: 1.2290819883346558%\n",
      "Validation Loss: 4.552988916635513\n",
      "Validation Accuracy: 2.941176414489746%\n",
      "Epoch 2, Loss: 4.554063558578491\n",
      "Training Accuracy: 3.552126407623291%\n",
      "Validation Loss: 4.415706738829613\n",
      "Validation Accuracy: 10.29411792755127%\n",
      "Epoch 3, Loss: 4.459620580077171\n",
      "Training Accuracy: 7.412514686584473%\n",
      "Validation Loss: 4.291141033172607\n",
      "Validation Accuracy: 17.54901885986328%\n",
      "Epoch 4, Loss: 4.337478503584862\n",
      "Training Accuracy: 16.120710372924805%\n",
      "Validation Loss: 4.151989296078682\n",
      "Validation Accuracy: 28.52941131591797%\n",
      "Epoch 5, Loss: 4.196594052016735\n",
      "Training Accuracy: 27.983421325683594%\n",
      "Validation Loss: 3.998853988945484\n",
      "Validation Accuracy: 40.0%\n",
      "Epoch 6, Loss: 4.079325683414936\n",
      "Training Accuracy: 34.222660064697266%\n",
      "Validation Loss: 3.8673679307103157\n",
      "Validation Accuracy: 45.882354736328125%\n",
      "Epoch 7, Loss: 4.030183382332325\n",
      "Training Accuracy: 37.20534896850586%\n",
      "Validation Loss: 3.766686365008354\n",
      "Validation Accuracy: 49.313724517822266%\n",
      "Epoch 8, Loss: 3.856865458190441\n",
      "Training Accuracy: 46.748714447021484%\n",
      "Validation Loss: 3.6219556108117104\n",
      "Validation Accuracy: 53.431373596191406%\n",
      "Epoch 9, Loss: 3.8747559189796448\n",
      "Training Accuracy: 40.73688888549805%\n",
      "Validation Loss: 3.536568269133568\n",
      "Validation Accuracy: 55.19607925415039%\n",
      "Epoch 10, Loss: 3.712760843336582\n",
      "Training Accuracy: 50.08384323120117%\n",
      "Validation Loss: 3.419191412627697\n",
      "Validation Accuracy: 57.74509811401367%\n",
      "Epoch 11, Loss: 3.6773953661322594\n",
      "Training Accuracy: 46.88862991333008%\n",
      "Validation Loss: 3.326072432100773\n",
      "Validation Accuracy: 59.509803771972656%\n",
      "Epoch 12, Loss: 3.5480712205171585\n",
      "Training Accuracy: 50.45787811279297%\n",
      "Validation Loss: 3.225085601210594\n",
      "Validation Accuracy: 64.50980377197266%\n",
      "Epoch 13, Loss: 3.47204926609993\n",
      "Training Accuracy: 53.796485900878906%\n",
      "Validation Loss: 3.1188851594924927\n",
      "Validation Accuracy: 65.49019622802734%\n",
      "Epoch 14, Loss: 3.449963577091694\n",
      "Training Accuracy: 52.0384407043457%\n",
      "Validation Loss: 3.0347191467881203\n",
      "Validation Accuracy: 66.76470947265625%\n",
      "Epoch 15, Loss: 3.3594227358698845\n",
      "Training Accuracy: 56.50408935546875%\n",
      "Validation Loss: 2.975100629031658\n",
      "Validation Accuracy: 66.86274719238281%\n",
      "Epoch 16, Loss: 3.2739028334617615\n",
      "Training Accuracy: 56.64307403564453%\n",
      "Validation Loss: 2.8650436624884605\n",
      "Validation Accuracy: 68.52941131591797%\n",
      "Epoch 17, Loss: 3.1946323961019516\n",
      "Training Accuracy: 57.082523345947266%\n",
      "Validation Loss: 2.7979561388492584\n",
      "Validation Accuracy: 71.2745132446289%\n",
      "Epoch 18, Loss: 3.047556459903717\n",
      "Training Accuracy: 62.09601593017578%\n",
      "Validation Loss: 2.7086353823542595\n",
      "Validation Accuracy: 70.39215850830078%\n",
      "Epoch 19, Loss: 2.993891626596451\n",
      "Training Accuracy: 61.73563003540039%\n",
      "Validation Loss: 2.6066428162157536\n",
      "Validation Accuracy: 71.47058868408203%\n",
      "Epoch 20, Loss: 3.0906003788113594\n",
      "Training Accuracy: 56.766727447509766%\n",
      "Validation Loss: 2.5924238190054893\n",
      "Validation Accuracy: 72.35294342041016%\n",
      "Epoch 21, Loss: 2.994565337896347\n",
      "Training Accuracy: 59.30573654174805%\n",
      "Validation Loss: 2.5120411328971386\n",
      "Validation Accuracy: 72.54901885986328%\n",
      "Epoch 22, Loss: 2.7633105739951134\n",
      "Training Accuracy: 66.95191192626953%\n",
      "Validation Loss: 2.377707041800022\n",
      "Validation Accuracy: 75.88235473632812%\n",
      "Epoch 23, Loss: 2.8782817274332047\n",
      "Training Accuracy: 60.50873947143555%\n",
      "Validation Loss: 2.3856435641646385\n",
      "Validation Accuracy: 74.50980377197266%\n",
      "Epoch 24, Loss: 2.8055005855858326\n",
      "Training Accuracy: 62.66142654418945%\n",
      "Validation Loss: 2.3495073057711124\n",
      "Validation Accuracy: 72.64705657958984%\n",
      "Epoch 25, Loss: 2.553100973367691\n",
      "Training Accuracy: 70.50897979736328%\n",
      "Validation Loss: 2.233086723834276\n",
      "Validation Accuracy: 75.78431701660156%\n",
      "Epoch 26, Loss: 2.680082432925701\n",
      "Training Accuracy: 65.5979232788086%\n",
      "Validation Loss: 2.232802599668503\n",
      "Validation Accuracy: 76.07843017578125%\n",
      "Epoch 27, Loss: 2.594241935759783\n",
      "Training Accuracy: 67.4583511352539%\n",
      "Validation Loss: 2.1907545290887356\n",
      "Validation Accuracy: 75.39215850830078%\n",
      "Epoch 28, Loss: 2.761344574391842\n",
      "Training Accuracy: 58.67244338989258%\n",
      "Validation Loss: 2.124176736921072\n",
      "Validation Accuracy: 75.29412078857422%\n",
      "Epoch 29, Loss: 2.5138129703700542\n",
      "Training Accuracy: 68.55541229248047%\n",
      "Validation Loss: 2.093162428587675\n",
      "Validation Accuracy: 76.5686264038086%\n",
      "Epoch 30, Loss: 2.468462146818638\n",
      "Training Accuracy: 68.8144760131836%\n",
      "Validation Loss: 2.021245803683996\n",
      "Validation Accuracy: 77.35294342041016%\n",
      "Epoch 31, Loss: 2.55097783729434\n",
      "Training Accuracy: 64.19821166992188%\n",
      "Validation Loss: 1.9617619402706623\n",
      "Validation Accuracy: 78.13725280761719%\n",
      "Epoch 32, Loss: 2.5999528132379055\n",
      "Training Accuracy: 61.16567611694336%\n",
      "Validation Loss: 1.9439635016024113\n",
      "Validation Accuracy: 78.03921508789062%\n",
      "Epoch 33, Loss: 2.4997144006192684\n",
      "Training Accuracy: 65.05472564697266%\n",
      "Validation Loss: 1.9647484309971333\n",
      "Validation Accuracy: 76.76470947265625%\n",
      "Epoch 34, Loss: 2.410301212221384\n",
      "Training Accuracy: 65.98516082763672%\n",
      "Validation Loss: 1.844163216650486\n",
      "Validation Accuracy: 78.7254867553711%\n",
      "Epoch 35, Loss: 2.4061720743775368\n",
      "Training Accuracy: 65.0478286743164%\n",
      "Validation Loss: 1.8527619242668152\n",
      "Validation Accuracy: 78.62744903564453%\n",
      "Epoch 36, Loss: 2.442733805626631\n",
      "Training Accuracy: 64.51164245605469%\n",
      "Validation Loss: 1.8147662691771984\n",
      "Validation Accuracy: 78.82353210449219%\n",
      "Epoch 37, Loss: 2.4433738626539707\n",
      "Training Accuracy: 63.38312530517578%\n",
      "Validation Loss: 1.8233619816601276\n",
      "Validation Accuracy: 77.64705657958984%\n",
      "Epoch 38, Loss: 2.407078504562378\n",
      "Training Accuracy: 63.065277099609375%\n",
      "Validation Loss: 1.7794379778206348\n",
      "Validation Accuracy: 78.7254867553711%\n",
      "Epoch 39, Loss: 2.4705477990210056\n",
      "Training Accuracy: 60.857303619384766%\n",
      "Validation Loss: 1.7965952828526497\n",
      "Validation Accuracy: 78.23529052734375%\n",
      "Epoch 40, Loss: 2.3481892868876457\n",
      "Training Accuracy: 63.39674758911133%\n",
      "Validation Loss: 1.6657848674803972\n",
      "Validation Accuracy: 79.80392456054688%\n",
      "Epoch 41, Loss: 2.3351046666502953\n",
      "Training Accuracy: 64.2518310546875%\n",
      "Validation Loss: 1.6994632072746754\n",
      "Validation Accuracy: 80.09803771972656%\n",
      "Epoch 42, Loss: 2.210964534431696\n",
      "Training Accuracy: 68.2448501586914%\n",
      "Validation Loss: 1.6623902209103107\n",
      "Validation Accuracy: 79.80392456054688%\n",
      "Epoch 43, Loss: 2.4711300395429134\n",
      "Training Accuracy: 59.934669494628906%\n",
      "Validation Loss: 1.7076266072690487\n",
      "Validation Accuracy: 79.01960754394531%\n",
      "Epoch 44, Loss: 2.1099152378737926\n",
      "Training Accuracy: 70.16136932373047%\n",
      "Validation Loss: 1.5675053391605616\n",
      "Validation Accuracy: 81.37255096435547%\n",
      "Epoch 45, Loss: 2.1107683666050434\n",
      "Training Accuracy: 69.96940612792969%\n",
      "Validation Loss: 1.5761441346257925\n",
      "Validation Accuracy: 80.98039245605469%\n",
      "Epoch 46, Loss: 1.91594348102808\n",
      "Training Accuracy: 74.09849548339844%\n",
      "Validation Loss: 1.5240588244050741\n",
      "Validation Accuracy: 82.64705657958984%\n",
      "Epoch 47, Loss: 2.32537411339581\n",
      "Training Accuracy: 62.82160568237305%\n",
      "Validation Loss: 1.56724994443357\n",
      "Validation Accuracy: 81.07843017578125%\n",
      "Epoch 48, Loss: 2.3354810252785683\n",
      "Training Accuracy: 62.915828704833984%\n",
      "Validation Loss: 1.6367391031235456\n",
      "Validation Accuracy: 78.13725280761719%\n",
      "Epoch 49, Loss: 2.248765531927347\n",
      "Training Accuracy: 64.88490295410156%\n",
      "Validation Loss: 1.5691198483109474\n",
      "Validation Accuracy: 79.90196228027344%\n",
      "Epoch 50, Loss: 2.2373628094792366\n",
      "Training Accuracy: 65.53263854980469%\n",
      "Validation Loss: 1.5199106056243181\n",
      "Validation Accuracy: 80.5882339477539%\n",
      "Epoch 51, Loss: 1.9748798198997974\n",
      "Training Accuracy: 72.58331298828125%\n",
      "Validation Loss: 1.4513060487806797\n",
      "Validation Accuracy: 83.23529052734375%\n",
      "Epoch 52, Loss: 2.0766868889331818\n",
      "Training Accuracy: 68.8314208984375%\n",
      "Validation Loss: 1.4532748311758041\n",
      "Validation Accuracy: 82.1568603515625%\n",
      "Epoch 53, Loss: 1.9208863079547882\n",
      "Training Accuracy: 72.70474243164062%\n",
      "Validation Loss: 1.381631050258875\n",
      "Validation Accuracy: 84.01960754394531%\n",
      "Epoch 54, Loss: 2.0922031570225954\n",
      "Training Accuracy: 67.05142974853516%\n",
      "Validation Loss: 1.4435667991638184\n",
      "Validation Accuracy: 82.2549057006836%\n",
      "Epoch 55, Loss: 2.0423516929149628\n",
      "Training Accuracy: 68.3178482055664%\n",
      "Validation Loss: 1.4709311537444592\n",
      "Validation Accuracy: 81.17646789550781%\n",
      "Epoch 56, Loss: 2.004956064745784\n",
      "Training Accuracy: 70.9841537475586%\n",
      "Validation Loss: 1.432767728343606\n",
      "Validation Accuracy: 81.5686264038086%\n",
      "Epoch 57, Loss: 1.8880830351263285\n",
      "Training Accuracy: 72.71250915527344%\n",
      "Validation Loss: 1.3737174402922392\n",
      "Validation Accuracy: 82.8431396484375%\n",
      "Epoch 58, Loss: 2.1153410989791155\n",
      "Training Accuracy: 64.78033447265625%\n",
      "Validation Loss: 1.3921512104570866\n",
      "Validation Accuracy: 82.35294342041016%\n",
      "Epoch 59, Loss: 1.8790359571576118\n",
      "Training Accuracy: 71.61061096191406%\n",
      "Validation Loss: 1.3396189361810684\n",
      "Validation Accuracy: 82.8431396484375%\n",
      "Epoch 60, Loss: 1.8640753030776978\n",
      "Training Accuracy: 71.49823760986328%\n",
      "Validation Loss: 1.3095925077795982\n",
      "Validation Accuracy: 83.92156982421875%\n",
      "Epoch 61, Loss: 1.9235846418887377\n",
      "Training Accuracy: 70.03030395507812%\n",
      "Validation Loss: 1.3450431246310472\n",
      "Validation Accuracy: 82.35294342041016%\n",
      "Epoch 62, Loss: 2.0917370095849037\n",
      "Training Accuracy: 66.1165771484375%\n",
      "Validation Loss: 1.4125923309475183\n",
      "Validation Accuracy: 81.5686264038086%\n",
      "Epoch 63, Loss: 1.9907496124505997\n",
      "Training Accuracy: 70.09403228759766%\n",
      "Validation Loss: 1.317165318876505\n",
      "Validation Accuracy: 83.23529052734375%\n",
      "Epoch 64, Loss: 2.0909071937203407\n",
      "Training Accuracy: 66.1043472290039%\n",
      "Validation Loss: 1.3351808991283178\n",
      "Validation Accuracy: 81.96078491210938%\n",
      "Epoch 65, Loss: 2.1327213142067194\n",
      "Training Accuracy: 65.38261413574219%\n",
      "Validation Loss: 1.3116114065051079\n",
      "Validation Accuracy: 82.05882263183594%\n",
      "Epoch 66, Loss: 1.7567022871226072\n",
      "Training Accuracy: 75.260986328125%\n",
      "Validation Loss: 1.250436894595623\n",
      "Validation Accuracy: 83.4313735961914%\n",
      "Epoch 67, Loss: 2.026752029545605\n",
      "Training Accuracy: 67.2166748046875%\n",
      "Validation Loss: 1.29258231818676\n",
      "Validation Accuracy: 82.45098114013672%\n",
      "Epoch 68, Loss: 1.792038206011057\n",
      "Training Accuracy: 74.86400604248047%\n",
      "Validation Loss: 1.2381847854703665\n",
      "Validation Accuracy: 83.7254867553711%\n",
      "Epoch 69, Loss: 2.112528033554554\n",
      "Training Accuracy: 64.63471984863281%\n",
      "Validation Loss: 1.3033449407666922\n",
      "Validation Accuracy: 82.1568603515625%\n",
      "Epoch 70, Loss: 1.9215825721621513\n",
      "Training Accuracy: 70.69618225097656%\n",
      "Validation Loss: 1.2290086783468723\n",
      "Validation Accuracy: 83.33333587646484%\n",
      "Epoch 71, Loss: 1.988851984962821\n",
      "Training Accuracy: 67.3792724609375%\n",
      "Validation Loss: 1.2531266938894987\n",
      "Validation Accuracy: 83.92156982421875%\n",
      "Epoch 72, Loss: 1.9018568713217974\n",
      "Training Accuracy: 70.37712860107422%\n",
      "Validation Loss: 1.2454823832958937\n",
      "Validation Accuracy: 84.01960754394531%\n",
      "Epoch 73, Loss: 2.0210857409983873\n",
      "Training Accuracy: 65.52398681640625%\n",
      "Validation Loss: 1.323973573744297\n",
      "Validation Accuracy: 81.07843017578125%\n",
      "Epoch 74, Loss: 1.999102622270584\n",
      "Training Accuracy: 66.5810775756836%\n",
      "Validation Loss: 1.252445885911584\n",
      "Validation Accuracy: 83.03921508789062%\n",
      "Epoch 75, Loss: 1.9177729487419128\n",
      "Training Accuracy: 71.0334701538086%\n",
      "Validation Loss: 1.1911330185830593\n",
      "Validation Accuracy: 83.62744903564453%\n",
      "Epoch 76, Loss: 1.8496697712689638\n",
      "Training Accuracy: 70.98252868652344%\n",
      "Validation Loss: 1.222430270165205\n",
      "Validation Accuracy: 83.92156982421875%\n",
      "Epoch 77, Loss: 2.0373349115252495\n",
      "Training Accuracy: 66.93231201171875%\n",
      "Validation Loss: 1.2496711313724518\n",
      "Validation Accuracy: 83.03921508789062%\n",
      "Epoch 78, Loss: 1.6307021602988243\n",
      "Training Accuracy: 75.8463134765625%\n",
      "Validation Loss: 1.1352490056306124\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 79, Loss: 1.9185495134443045\n",
      "Training Accuracy: 67.60610961914062%\n",
      "Validation Loss: 1.1755009833723307\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 80, Loss: 1.7745619993656874\n",
      "Training Accuracy: 72.18391418457031%\n",
      "Validation Loss: 1.1728130988776684\n",
      "Validation Accuracy: 84.31372833251953%\n",
      "Epoch 81, Loss: 1.8862804202362895\n",
      "Training Accuracy: 70.52241516113281%\n",
      "Validation Loss: 1.1325240572914481\n",
      "Validation Accuracy: 84.70587921142578%\n",
      "Epoch 82, Loss: 1.9127803416922688\n",
      "Training Accuracy: 68.67474365234375%\n",
      "Validation Loss: 1.1441407650709152\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 83, Loss: 1.5746539328247309\n",
      "Training Accuracy: 78.2022476196289%\n",
      "Validation Loss: 1.1012499425560236\n",
      "Validation Accuracy: 85.09803771972656%\n",
      "Epoch 84, Loss: 1.967127088457346\n",
      "Training Accuracy: 67.98014831542969%\n",
      "Validation Loss: 1.2220187205821276\n",
      "Validation Accuracy: 83.33333587646484%\n",
      "Epoch 85, Loss: 1.9578268863260746\n",
      "Training Accuracy: 68.17329406738281%\n",
      "Validation Loss: 1.166933273896575\n",
      "Validation Accuracy: 83.62744903564453%\n",
      "Epoch 86, Loss: 2.083948213607073\n",
      "Training Accuracy: 63.936641693115234%\n",
      "Validation Loss: 1.2183214016258717\n",
      "Validation Accuracy: 82.45098114013672%\n",
      "Epoch 87, Loss: 1.8539106231182814\n",
      "Training Accuracy: 69.3920669555664%\n",
      "Validation Loss: 1.1583900079131126\n",
      "Validation Accuracy: 83.92156982421875%\n",
      "Epoch 88, Loss: 1.7591568231582642\n",
      "Training Accuracy: 72.65152740478516%\n",
      "Validation Loss: 1.1328099463135004\n",
      "Validation Accuracy: 84.50980377197266%\n",
      "Epoch 89, Loss: 1.6982615031301975\n",
      "Training Accuracy: 74.62157440185547%\n",
      "Validation Loss: 1.0787451304495335\n",
      "Validation Accuracy: 85.5882339477539%\n",
      "Epoch 90, Loss: 1.8458711318671703\n",
      "Training Accuracy: 71.13317108154297%\n",
      "Validation Loss: 1.0912666907534003\n",
      "Validation Accuracy: 84.90196228027344%\n",
      "Epoch 91, Loss: 1.7178280372172594\n",
      "Training Accuracy: 73.09864044189453%\n",
      "Validation Loss: 1.109808774664998\n",
      "Validation Accuracy: 85.19607543945312%\n",
      "Epoch 92, Loss: 1.861641677096486\n",
      "Training Accuracy: 70.09011840820312%\n",
      "Validation Loss: 1.09178149048239\n",
      "Validation Accuracy: 84.4117660522461%\n",
      "Epoch 93, Loss: 1.9640253633260727\n",
      "Training Accuracy: 65.4367904663086%\n",
      "Validation Loss: 1.1864193845540285\n",
      "Validation Accuracy: 82.64705657958984%\n",
      "Epoch 94, Loss: 1.6846752585843205\n",
      "Training Accuracy: 73.9443588256836%\n",
      "Validation Loss: 1.1063677426427603\n",
      "Validation Accuracy: 84.90196228027344%\n",
      "Epoch 95, Loss: 2.1184187792241573\n",
      "Training Accuracy: 62.33305740356445%\n",
      "Validation Loss: 1.1525766644626856\n",
      "Validation Accuracy: 83.03921508789062%\n",
      "Epoch 96, Loss: 1.5754513889551163\n",
      "Training Accuracy: 77.62272644042969%\n",
      "Validation Loss: 1.05696034245193\n",
      "Validation Accuracy: 84.60784149169922%\n",
      "Epoch 97, Loss: 1.8109510205686092\n",
      "Training Accuracy: 72.60228729248047%\n",
      "Validation Loss: 1.0921735912561417\n",
      "Validation Accuracy: 84.70587921142578%\n",
      "Epoch 98, Loss: 2.0856971871107817\n",
      "Training Accuracy: 62.22578811645508%\n",
      "Validation Loss: 1.1067271195352077\n",
      "Validation Accuracy: 84.50980377197266%\n",
      "Epoch 99, Loss: 1.7588776722550392\n",
      "Training Accuracy: 71.04591369628906%\n",
      "Validation Loss: 1.0277948202565312\n",
      "Validation Accuracy: 85.29412078857422%\n",
      "Epoch 100, Loss: 1.504854573868215\n",
      "Training Accuracy: 78.64952850341797%\n",
      "Validation Loss: 1.0382924610748887\n",
      "Validation Accuracy: 85.19607543945312%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "no_improvement_counter = 0\n",
    "patience = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    for data, target_a, target_b, lam in mixup_loader(train_loader):\n",
    "        data, target_a, target_b = data.to(device), target_a.to(device), target_b.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target_a.size(0)\n",
    "        correct += (lam * predicted.eq(target_a.data).cpu().sum().float() + (1 - lam) * predicted.eq(target_b.data).cpu().sum().float())\n",
    "\n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    print(f\"Training Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    validation_loss = 0\n",
    "    best_validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "    # Print validation accuracy for each epoch\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {validation_loss / len(val_loader)}\")\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_accuracy\n",
    "        no_improvement_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        no_improvement_counter += 1\n",
    "\n",
    "    if no_improvement_counter >= patience:\n",
    "        print(\"Early stopping: No improvement for {} epochs.\".format(patience))\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet50_flowers102_mixup.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHuQlA4NVoX9",
    "outputId": "29b33e96-477d-4132-817b-24bf977526ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1083086179328088\n",
      "Test Accuracy: 83.07041931152344%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model (if not already loaded)\n",
    "model.load_state_dict(torch.load('resnet50_flowers102_mixup.pth'))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        test_correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "test_accuracy = 100 * test_correct / total\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define data augmentation transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # Randomly crop and resize\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip horizontally\n",
    "        transforms.RandomRotation(30),  # Randomly rotate by up to 30 degrees\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n",
    "        transforms.RandomGrayscale(p=0.2),  # Convert to grayscale with a 20% probability\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),  # Random perspective transformation\n",
    "        transforms.RandomVerticalFlip(),  # Randomly flip vertically\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize for validation and test\n",
    "        transforms.CenterCrop(224),  # Center crop for validation and test\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize for validation and test\n",
    "        transforms.CenterCrop(224),  # Center crop for validation and test\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Apply the data augmentation transformations to your datasets\n",
    "train_dataset = Flowers102(\n",
    "    root='./data',\n",
    "    split='train',\n",
    "    transform=data_transforms['train'],  # Use data augmentation for training\n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_dataset = Flowers102(\n",
    "    root='./data',\n",
    "    split='val',\n",
    "    transform=data_transforms['val'],  # Use validation data transformations\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = Flowers102(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    transform=data_transforms['test'],  # Use test data transformations\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "batch_size = 64  # You can adjust the batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the MixUp function\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# Create a MixUp data loader\n",
    "def mixup_loader(dataloader, alpha=1.0):\n",
    "    for data, target in dataloader:\n",
    "        data, target_a, target_b, lam = mixup_data(data, target, alpha)\n",
    "        yield data, target_a, target_b, lam\n",
    "        \n",
    "# Define the ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc.requires_grad = True\n",
    "\n",
    "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
    "model.fc = nn.Linear(model.fc.in_features, 102)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.682889610528946\n",
      "Training Accuracy: 0.7725469470024109%\n",
      "Validation Loss: 4.593235030770302\n",
      "Validation Accuracy: 0.9803921580314636%\n",
      "Epoch 2, Loss: 4.628222018480301\n",
      "Training Accuracy: 1.229355812072754%\n",
      "Validation Loss: 4.526539191603661\n",
      "Validation Accuracy: 4.019608020782471%\n",
      "Epoch 3, Loss: 4.589940443634987\n",
      "Training Accuracy: 1.79043447971344%\n",
      "Validation Loss: 4.459864974021912\n",
      "Validation Accuracy: 6.56862735748291%\n",
      "Epoch 4, Loss: 4.552561700344086\n",
      "Training Accuracy: 3.189758539199829%\n",
      "Validation Loss: 4.392927944660187\n",
      "Validation Accuracy: 9.607843399047852%\n",
      "Epoch 5, Loss: 4.509923219680786\n",
      "Training Accuracy: 5.538421630859375%\n",
      "Validation Loss: 4.326731137931347\n",
      "Validation Accuracy: 13.13725471496582%\n",
      "Epoch 6, Loss: 4.449300706386566\n",
      "Training Accuracy: 9.377697944641113%\n",
      "Validation Loss: 4.25895918160677\n",
      "Validation Accuracy: 13.43137264251709%\n",
      "Epoch 7, Loss: 4.4689967930316925\n",
      "Training Accuracy: 6.746631622314453%\n",
      "Validation Loss: 4.219809450209141\n",
      "Validation Accuracy: 15.686274528503418%\n",
      "Epoch 8, Loss: 4.393914744257927\n",
      "Training Accuracy: 11.765530586242676%\n",
      "Validation Loss: 4.156856395304203\n",
      "Validation Accuracy: 20.19607925415039%\n",
      "Epoch 9, Loss: 4.355482861399651\n",
      "Training Accuracy: 12.094409942626953%\n",
      "Validation Loss: 4.09490031003952\n",
      "Validation Accuracy: 18.33333396911621%\n",
      "Epoch 10, Loss: 4.336794540286064\n",
      "Training Accuracy: 14.408425331115723%\n",
      "Validation Loss: 4.047813042998314\n",
      "Validation Accuracy: 20.882352828979492%\n",
      "Epoch 11, Loss: 4.287278264760971\n",
      "Training Accuracy: 17.05088233947754%\n",
      "Validation Loss: 3.9766716361045837\n",
      "Validation Accuracy: 25.19607925415039%\n",
      "Epoch 12, Loss: 4.259620741009712\n",
      "Training Accuracy: 17.916580200195312%\n",
      "Validation Loss: 3.9259584471583366\n",
      "Validation Accuracy: 24.3137264251709%\n",
      "Epoch 13, Loss: 4.221779488027096\n",
      "Training Accuracy: 18.165420532226562%\n",
      "Validation Loss: 3.871009446680546\n",
      "Validation Accuracy: 26.47058868408203%\n",
      "Epoch 14, Loss: 4.166405886411667\n",
      "Training Accuracy: 23.341136932373047%\n",
      "Validation Loss: 3.8190694972872734\n",
      "Validation Accuracy: 27.745098114013672%\n",
      "Epoch 15, Loss: 4.131341725587845\n",
      "Training Accuracy: 21.971729278564453%\n",
      "Validation Loss: 3.754014402627945\n",
      "Validation Accuracy: 30.490196228027344%\n",
      "Epoch 16, Loss: 4.117304369807243\n",
      "Training Accuracy: 23.792606353759766%\n",
      "Validation Loss: 3.7139177098870277\n",
      "Validation Accuracy: 31.372549057006836%\n",
      "Epoch 17, Loss: 4.104168802499771\n",
      "Training Accuracy: 24.413692474365234%\n",
      "Validation Loss: 3.6873524487018585\n",
      "Validation Accuracy: 30.294116973876953%\n",
      "Epoch 18, Loss: 4.082830160856247\n",
      "Training Accuracy: 23.179235458374023%\n",
      "Validation Loss: 3.60955860465765\n",
      "Validation Accuracy: 37.25490188598633%\n",
      "Epoch 19, Loss: 4.05411821603775\n",
      "Training Accuracy: 24.383588790893555%\n",
      "Validation Loss: 3.5988094955682755\n",
      "Validation Accuracy: 31.66666603088379%\n",
      "Epoch 20, Loss: 4.0043716207146645\n",
      "Training Accuracy: 26.681596755981445%\n",
      "Validation Loss: 3.5440073907375336\n",
      "Validation Accuracy: 35.588233947753906%\n",
      "Epoch 21, Loss: 3.9844187051057816\n",
      "Training Accuracy: 25.240745544433594%\n",
      "Validation Loss: 3.4979247748851776\n",
      "Validation Accuracy: 35.98039245605469%\n",
      "Epoch 22, Loss: 3.897147476673126\n",
      "Training Accuracy: 29.851823806762695%\n",
      "Validation Loss: 3.438527338206768\n",
      "Validation Accuracy: 37.54901885986328%\n",
      "Epoch 23, Loss: 3.9143386110663414\n",
      "Training Accuracy: 28.45078468322754%\n",
      "Validation Loss: 3.4022950306534767\n",
      "Validation Accuracy: 37.64706039428711%\n",
      "Epoch 24, Loss: 3.860793098807335\n",
      "Training Accuracy: 30.66683006286621%\n",
      "Validation Loss: 3.3523333370685577\n",
      "Validation Accuracy: 37.843135833740234%\n",
      "Epoch 25, Loss: 3.8984941467642784\n",
      "Training Accuracy: 29.44120979309082%\n",
      "Validation Loss: 3.3298783898353577\n",
      "Validation Accuracy: 38.33333206176758%\n",
      "Epoch 26, Loss: 3.833524666726589\n",
      "Training Accuracy: 29.2237491607666%\n",
      "Validation Loss: 3.3141351267695427\n",
      "Validation Accuracy: 37.54901885986328%\n",
      "Epoch 27, Loss: 3.834408327937126\n",
      "Training Accuracy: 27.805086135864258%\n",
      "Validation Loss: 3.242268607020378\n",
      "Validation Accuracy: 40.0%\n",
      "Epoch 28, Loss: 3.8211938813328743\n",
      "Training Accuracy: 28.01982307434082%\n",
      "Validation Loss: 3.1891765370965004\n",
      "Validation Accuracy: 42.54901885986328%\n",
      "Epoch 29, Loss: 3.773971349000931\n",
      "Training Accuracy: 30.529747009277344%\n",
      "Validation Loss: 3.1799364909529686\n",
      "Validation Accuracy: 40.98039245605469%\n",
      "Epoch 30, Loss: 3.8414553850889206\n",
      "Training Accuracy: 27.48000717163086%\n",
      "Validation Loss: 3.186272941529751\n",
      "Validation Accuracy: 40.490196228027344%\n",
      "Epoch 31, Loss: 3.7324964106082916\n",
      "Training Accuracy: 30.700353622436523%\n",
      "Validation Loss: 3.10759836435318\n",
      "Validation Accuracy: 42.94117736816406%\n",
      "Epoch 32, Loss: 3.736769452691078\n",
      "Training Accuracy: 31.187278747558594%\n",
      "Validation Loss: 3.094505213201046\n",
      "Validation Accuracy: 41.960784912109375%\n",
      "Epoch 33, Loss: 3.61434393376112\n",
      "Training Accuracy: 36.254310607910156%\n",
      "Validation Loss: 3.034797914326191\n",
      "Validation Accuracy: 45.39215850830078%\n",
      "Epoch 34, Loss: 3.634563960134983\n",
      "Training Accuracy: 35.40134048461914%\n",
      "Validation Loss: 2.9983759373426437\n",
      "Validation Accuracy: 44.70588302612305%\n",
      "Epoch 35, Loss: 3.606057457625866\n",
      "Training Accuracy: 35.64780044555664%\n",
      "Validation Loss: 2.966586507856846\n",
      "Validation Accuracy: 45.490196228027344%\n",
      "Epoch 36, Loss: 3.594469390809536\n",
      "Training Accuracy: 34.35256576538086%\n",
      "Validation Loss: 2.9394705444574356\n",
      "Validation Accuracy: 45.490196228027344%\n",
      "Epoch 37, Loss: 3.678648740053177\n",
      "Training Accuracy: 29.684993743896484%\n",
      "Validation Loss: 2.9510738775134087\n",
      "Validation Accuracy: 43.13725662231445%\n",
      "Epoch 38, Loss: 3.592655301094055\n",
      "Training Accuracy: 34.778038024902344%\n",
      "Validation Loss: 2.8936078399419785\n",
      "Validation Accuracy: 47.35293960571289%\n",
      "Epoch 39, Loss: 3.645119458436966\n",
      "Training Accuracy: 31.41419219970703%\n",
      "Validation Loss: 2.8983378782868385\n",
      "Validation Accuracy: 46.07843017578125%\n",
      "Epoch 40, Loss: 3.6089465394616127\n",
      "Training Accuracy: 31.92716407775879%\n",
      "Validation Loss: 2.841274231672287\n",
      "Validation Accuracy: 46.764705657958984%\n",
      "Epoch 41, Loss: 3.5902021303772926\n",
      "Training Accuracy: 31.542552947998047%\n",
      "Validation Loss: 2.825515851378441\n",
      "Validation Accuracy: 45.98039245605469%\n",
      "Epoch 42, Loss: 3.4788123220205307\n",
      "Training Accuracy: 36.513675689697266%\n",
      "Validation Loss: 2.750872563570738\n",
      "Validation Accuracy: 51.86274337768555%\n",
      "Epoch 43, Loss: 3.4498666524887085\n",
      "Training Accuracy: 37.40523910522461%\n",
      "Validation Loss: 2.745188105851412\n",
      "Validation Accuracy: 48.52941131591797%\n",
      "Epoch 44, Loss: 3.4787524938583374\n",
      "Training Accuracy: 36.2374267578125%\n",
      "Validation Loss: 2.7200673408806324\n",
      "Validation Accuracy: 49.411766052246094%\n",
      "Epoch 45, Loss: 3.510962262749672\n",
      "Training Accuracy: 35.30192565917969%\n",
      "Validation Loss: 2.7309431806206703\n",
      "Validation Accuracy: 49.2156867980957%\n",
      "Epoch 46, Loss: 3.4237899854779243\n",
      "Training Accuracy: 36.34105682373047%\n",
      "Validation Loss: 2.672857191413641\n",
      "Validation Accuracy: 51.07843017578125%\n",
      "Epoch 47, Loss: 3.4053849205374718\n",
      "Training Accuracy: 38.79106140136719%\n",
      "Validation Loss: 2.642744593322277\n",
      "Validation Accuracy: 51.27450942993164%\n",
      "Epoch 48, Loss: 3.543343350291252\n",
      "Training Accuracy: 32.40057373046875%\n",
      "Validation Loss: 2.6624296084046364\n",
      "Validation Accuracy: 51.07843017578125%\n",
      "Epoch 49, Loss: 3.4937219843268394\n",
      "Training Accuracy: 32.56043243408203%\n",
      "Validation Loss: 2.6633082553744316\n",
      "Validation Accuracy: 48.235294342041016%\n",
      "Epoch 50, Loss: 3.4587724432349205\n",
      "Training Accuracy: 33.87250900268555%\n",
      "Validation Loss: 2.5869998149573803\n",
      "Validation Accuracy: 51.568626403808594%\n",
      "Epoch 51, Loss: 3.3300761356949806\n",
      "Training Accuracy: 40.07658386230469%\n",
      "Validation Loss: 2.5500139966607094\n",
      "Validation Accuracy: 53.92156982421875%\n",
      "Epoch 52, Loss: 3.3850838020443916\n",
      "Training Accuracy: 38.830596923828125%\n",
      "Validation Loss: 2.56014621257782\n",
      "Validation Accuracy: 52.64706039428711%\n",
      "Epoch 53, Loss: 3.3097782880067825\n",
      "Training Accuracy: 38.51932144165039%\n",
      "Validation Loss: 2.5018787272274494\n",
      "Validation Accuracy: 54.313724517822266%\n",
      "Epoch 54, Loss: 3.422275982797146\n",
      "Training Accuracy: 33.957515716552734%\n",
      "Validation Loss: 2.536400191485882\n",
      "Validation Accuracy: 50.686275482177734%\n",
      "Epoch 55, Loss: 3.409221686422825\n",
      "Training Accuracy: 34.5617561340332%\n",
      "Validation Loss: 2.529341798275709\n",
      "Validation Accuracy: 50.588233947753906%\n",
      "Epoch 56, Loss: 3.376742735505104\n",
      "Training Accuracy: 35.89035415649414%\n",
      "Validation Loss: 2.499335553497076\n",
      "Validation Accuracy: 52.35293960571289%\n",
      "Epoch 57, Loss: 3.1450776159763336\n",
      "Training Accuracy: 42.195220947265625%\n",
      "Validation Loss: 2.389247253537178\n",
      "Validation Accuracy: 56.27450942993164%\n",
      "Epoch 58, Loss: 3.3668388798832893\n",
      "Training Accuracy: 36.37558364868164%\n",
      "Validation Loss: 2.482909258455038\n",
      "Validation Accuracy: 51.66666793823242%\n",
      "Epoch 59, Loss: 3.3740322068333626\n",
      "Training Accuracy: 35.30356979370117%\n",
      "Validation Loss: 2.4157914854586124\n",
      "Validation Accuracy: 54.60784149169922%\n",
      "Epoch 60, Loss: 3.3255803883075714\n",
      "Training Accuracy: 36.540367126464844%\n",
      "Validation Loss: 2.393672898411751\n",
      "Validation Accuracy: 55.490196228027344%\n",
      "Epoch 61, Loss: 3.2397937327623367\n",
      "Training Accuracy: 38.398216247558594%\n",
      "Validation Loss: 2.3772486709058285\n",
      "Validation Accuracy: 55.7843132019043%\n",
      "Epoch 62, Loss: 3.2527096420526505\n",
      "Training Accuracy: 38.38479995727539%\n",
      "Validation Loss: 2.3305519185960293\n",
      "Validation Accuracy: 58.039215087890625%\n",
      "Epoch 63, Loss: 3.3060273230075836\n",
      "Training Accuracy: 38.4080924987793%\n",
      "Validation Loss: 2.3760050386190414\n",
      "Validation Accuracy: 53.92156982421875%\n",
      "Epoch 64, Loss: 3.270815148949623\n",
      "Training Accuracy: 38.374168395996094%\n",
      "Validation Loss: 2.3794213570654392\n",
      "Validation Accuracy: 53.72549057006836%\n",
      "Epoch 65, Loss: 3.209204651415348\n",
      "Training Accuracy: 38.5003776550293%\n",
      "Validation Loss: 2.3177103213965893\n",
      "Validation Accuracy: 55.7843132019043%\n",
      "Epoch 66, Loss: 3.2720420360565186\n",
      "Training Accuracy: 38.325355529785156%\n",
      "Validation Loss: 2.323962088674307\n",
      "Validation Accuracy: 54.90196228027344%\n",
      "Epoch 67, Loss: 3.192863881587982\n",
      "Training Accuracy: 39.752506256103516%\n",
      "Validation Loss: 2.288852136582136\n",
      "Validation Accuracy: 55.19607925415039%\n",
      "Epoch 68, Loss: 3.1342577412724495\n",
      "Training Accuracy: 40.56793975830078%\n",
      "Validation Loss: 2.2445926181972027\n",
      "Validation Accuracy: 57.54901885986328%\n",
      "Epoch 69, Loss: 3.2225507646799088\n",
      "Training Accuracy: 38.7439079284668%\n",
      "Validation Loss: 2.263235241174698\n",
      "Validation Accuracy: 57.05882263183594%\n",
      "Epoch 70, Loss: 3.215535558760166\n",
      "Training Accuracy: 37.519256591796875%\n",
      "Validation Loss: 2.277590848505497\n",
      "Validation Accuracy: 54.80392074584961%\n",
      "Epoch 71, Loss: 3.2658628448843956\n",
      "Training Accuracy: 35.76572036743164%\n",
      "Validation Loss: 2.2611838318407536\n",
      "Validation Accuracy: 56.66666793823242%\n",
      "Epoch 72, Loss: 3.201315015554428\n",
      "Training Accuracy: 38.42389678955078%\n",
      "Validation Loss: 2.2524609714746475\n",
      "Validation Accuracy: 54.90196228027344%\n",
      "Epoch 73, Loss: 3.2450465261936188\n",
      "Training Accuracy: 37.67978286743164%\n",
      "Validation Loss: 2.210507284849882\n",
      "Validation Accuracy: 57.64706039428711%\n",
      "Epoch 74, Loss: 3.1490912064909935\n",
      "Training Accuracy: 38.41318130493164%\n",
      "Validation Loss: 2.2160770259797573\n",
      "Validation Accuracy: 57.35293960571289%\n",
      "Epoch 75, Loss: 3.24566563218832\n",
      "Training Accuracy: 36.32210159301758%\n",
      "Validation Loss: 2.1918803080916405\n",
      "Validation Accuracy: 56.3725471496582%\n",
      "Epoch 76, Loss: 3.1768878921866417\n",
      "Training Accuracy: 37.92108917236328%\n",
      "Validation Loss: 2.170086022466421\n",
      "Validation Accuracy: 57.35293960571289%\n",
      "Epoch 77, Loss: 3.1916800439357758\n",
      "Training Accuracy: 37.95085525512695%\n",
      "Validation Loss: 2.1896218955516815\n",
      "Validation Accuracy: 57.05882263183594%\n",
      "Epoch 78, Loss: 3.0433029904961586\n",
      "Training Accuracy: 43.2308349609375%\n",
      "Validation Loss: 2.110418628901243\n",
      "Validation Accuracy: 61.07843017578125%\n",
      "Epoch 79, Loss: 3.122875787317753\n",
      "Training Accuracy: 39.93650436401367%\n",
      "Validation Loss: 2.1055480763316154\n",
      "Validation Accuracy: 60.490196228027344%\n",
      "Epoch 80, Loss: 3.131268970668316\n",
      "Training Accuracy: 39.67856979370117%\n",
      "Validation Loss: 2.1028739996254444\n",
      "Validation Accuracy: 59.60784149169922%\n",
      "Epoch 81, Loss: 3.054508551955223\n",
      "Training Accuracy: 41.8508186340332%\n",
      "Validation Loss: 2.0544768944382668\n",
      "Validation Accuracy: 61.07843017578125%\n",
      "Epoch 82, Loss: 3.004926972091198\n",
      "Training Accuracy: 42.945709228515625%\n",
      "Validation Loss: 2.0575702153146267\n",
      "Validation Accuracy: 62.54901885986328%\n",
      "Epoch 83, Loss: 3.0332972556352615\n",
      "Training Accuracy: 41.896671295166016%\n",
      "Validation Loss: 2.0594307221472263\n",
      "Validation Accuracy: 60.29411697387695%\n",
      "Epoch 84, Loss: 3.175910532474518\n",
      "Training Accuracy: 35.968990325927734%\n",
      "Validation Loss: 2.0859080404043198\n",
      "Validation Accuracy: 58.13725662231445%\n",
      "Epoch 85, Loss: 2.9527353271842003\n",
      "Training Accuracy: 43.73844909667969%\n",
      "Validation Loss: 2.017107021063566\n",
      "Validation Accuracy: 61.960784912109375%\n",
      "Epoch 86, Loss: 3.182344950735569\n",
      "Training Accuracy: 37.57646560668945%\n",
      "Validation Loss: 2.057383269071579\n",
      "Validation Accuracy: 60.0%\n",
      "Epoch 87, Loss: 3.032626137137413\n",
      "Training Accuracy: 40.583770751953125%\n",
      "Validation Loss: 2.0110232420265675\n",
      "Validation Accuracy: 61.764705657958984%\n",
      "Epoch 88, Loss: 3.1401641219854355\n",
      "Training Accuracy: 38.611907958984375%\n",
      "Validation Loss: 2.028278924524784\n",
      "Validation Accuracy: 61.764705657958984%\n",
      "Epoch 89, Loss: 3.2124639078974724\n",
      "Training Accuracy: 36.552040100097656%\n",
      "Validation Loss: 2.089873284101486\n",
      "Validation Accuracy: 56.3725471496582%\n",
      "Epoch 90, Loss: 2.946936309337616\n",
      "Training Accuracy: 43.172550201416016%\n",
      "Validation Loss: 1.9681494161486626\n",
      "Validation Accuracy: 62.94117736816406%\n",
      "Epoch 91, Loss: 3.0576282516121864\n",
      "Training Accuracy: 40.94547653198242%\n",
      "Validation Loss: 2.026430830359459\n",
      "Validation Accuracy: 60.09803771972656%\n",
      "Epoch 92, Loss: 3.0869141966104507\n",
      "Training Accuracy: 40.056888580322266%\n",
      "Validation Loss: 1.9825565926730633\n",
      "Validation Accuracy: 62.35293960571289%\n",
      "Epoch 93, Loss: 3.155850403010845\n",
      "Training Accuracy: 37.52043533325195%\n",
      "Validation Loss: 2.0012722462415695\n",
      "Validation Accuracy: 60.882354736328125%\n",
      "Epoch 94, Loss: 2.8943320736289024\n",
      "Training Accuracy: 44.71036148071289%\n",
      "Validation Loss: 1.9600938744843006\n",
      "Validation Accuracy: 62.05882263183594%\n",
      "Epoch 95, Loss: 3.0456391237676144\n",
      "Training Accuracy: 39.54928207397461%\n",
      "Validation Loss: 1.953079629689455\n",
      "Validation Accuracy: 61.3725471496582%\n",
      "Epoch 96, Loss: 2.951663512736559\n",
      "Training Accuracy: 44.47853469848633%\n",
      "Validation Loss: 1.9551552347838879\n",
      "Validation Accuracy: 60.39215850830078%\n",
      "Epoch 97, Loss: 3.050838477909565\n",
      "Training Accuracy: 39.868629455566406%\n",
      "Validation Loss: 1.911494616419077\n",
      "Validation Accuracy: 63.33333206176758%\n",
      "Epoch 98, Loss: 2.8751759827136993\n",
      "Training Accuracy: 44.380435943603516%\n",
      "Validation Loss: 1.873224463313818\n",
      "Validation Accuracy: 64.80392456054688%\n",
      "Epoch 99, Loss: 2.9457984790205956\n",
      "Training Accuracy: 42.47505569458008%\n",
      "Validation Loss: 1.858930241316557\n",
      "Validation Accuracy: 65.78431701660156%\n",
      "Epoch 100, Loss: 2.968543365597725\n",
      "Training Accuracy: 41.59189224243164%\n",
      "Validation Loss: 1.8761839754879475\n",
      "Validation Accuracy: 63.6274528503418%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "no_improvement_counter = 0\n",
    "patience = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    for data, target_a, target_b, lam in mixup_loader(train_loader):\n",
    "        data, target_a, target_b = data.to(device), target_a.to(device), target_b.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target_a.size(0)\n",
    "        correct += (lam * predicted.eq(target_a.data).cpu().sum().float() + (1 - lam) * predicted.eq(target_b.data).cpu().sum().float())\n",
    "\n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    print(f\"Training Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    validation_loss = 0\n",
    "    best_validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "    # Print validation accuracy for each epoch\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {validation_loss / len(val_loader)}\")\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_accuracy\n",
    "        no_improvement_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        no_improvement_counter += 1\n",
    "\n",
    "    if no_improvement_counter >= patience:\n",
    "        print(\"Early stopping: No improvement for {} epochs.\".format(patience))\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet50_flowers102_mixup.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9907307851808675\n",
      "Test Accuracy: 62.270286560058594%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model (if not already loaded)\n",
    "model.load_state_dict(torch.load('resnet50_flowers102_mixup.pth'))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        test_correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "test_accuracy = 100 * test_correct / total\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet-152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Flowers102\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the Flowers102 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Download the dataset (training split)\n",
    "train_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='train',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")\n",
    "\n",
    "# Download the dataset (validation split)\n",
    "val_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='val',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")\n",
    "\n",
    "# Download the dataset (test split)\n",
    "test_dataset = Flowers102(\n",
    "    root='./data',  # The root directory where the dataset will be saved\n",
    "    split='test',   # 'train' for the training set, 'test' for the test set\n",
    "    transform=transform,  # Apply the defined transformation\n",
    "    download=True  # Download if not already present\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the MixUp function\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# Create a MixUp data loader\n",
    "def mixup_loader(dataloader, alpha=1.0):\n",
    "    for data, target in dataloader:\n",
    "        data, target_a, target_b, lam = mixup_data(data, target, alpha)\n",
    "        yield data, target_a, target_b, lam\n",
    "\n",
    "# Define the ResNet-152 model\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc.requires_grad = True\n",
    "\n",
    "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
    "model.fc = nn.Linear(model.fc.in_features, 102)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.686394557356834\n",
      "Training Accuracy: 0.7857245802879333%\n",
      "Validation Loss: 4.578508660197258\n",
      "Validation Accuracy: 1.372549057006836%\n",
      "Epoch 2, Loss: 4.547796651721001\n",
      "Training Accuracy: 3.1319284439086914%\n",
      "Validation Loss: 4.410183101892471\n",
      "Validation Accuracy: 9.70588207244873%\n",
      "Epoch 3, Loss: 4.444122940301895\n",
      "Training Accuracy: 7.908377170562744%\n",
      "Validation Loss: 4.274492472410202\n",
      "Validation Accuracy: 22.254901885986328%\n",
      "Epoch 4, Loss: 4.288861200213432\n",
      "Training Accuracy: 18.87061309814453%\n",
      "Validation Loss: 4.12100300937891\n",
      "Validation Accuracy: 32.156864166259766%\n",
      "Epoch 5, Loss: 4.155911609530449\n",
      "Training Accuracy: 28.634626388549805%\n",
      "Validation Loss: 3.958118736743927\n",
      "Validation Accuracy: 42.156864166259766%\n",
      "Epoch 6, Loss: 4.0417996644973755\n",
      "Training Accuracy: 33.79977035522461%\n",
      "Validation Loss: 3.8295202925801277\n",
      "Validation Accuracy: 44.80392074584961%\n",
      "Epoch 7, Loss: 3.9592252746224403\n",
      "Training Accuracy: 38.86756896972656%\n",
      "Validation Loss: 3.7053838670253754\n",
      "Validation Accuracy: 52.843135833740234%\n",
      "Epoch 8, Loss: 3.8394047990441322\n",
      "Training Accuracy: 43.54913330078125%\n",
      "Validation Loss: 3.5774241387844086\n",
      "Validation Accuracy: 53.92156982421875%\n",
      "Epoch 9, Loss: 3.7142912670969963\n",
      "Training Accuracy: 47.38166427612305%\n",
      "Validation Loss: 3.4475734159350395\n",
      "Validation Accuracy: 59.117645263671875%\n",
      "Epoch 10, Loss: 3.6113398298621178\n",
      "Training Accuracy: 51.21638488769531%\n",
      "Validation Loss: 3.362274631857872\n",
      "Validation Accuracy: 59.313724517822266%\n",
      "Epoch 11, Loss: 3.522978365421295\n",
      "Training Accuracy: 52.47745895385742%\n",
      "Validation Loss: 3.22993952780962\n",
      "Validation Accuracy: 61.568626403808594%\n",
      "Epoch 12, Loss: 3.4367668703198433\n",
      "Training Accuracy: 53.55622100830078%\n",
      "Validation Loss: 3.1220596358180046\n",
      "Validation Accuracy: 63.6274528503418%\n",
      "Epoch 13, Loss: 3.3422721698880196\n",
      "Training Accuracy: 56.545589447021484%\n",
      "Validation Loss: 3.042769342660904\n",
      "Validation Accuracy: 65.29412078857422%\n",
      "Epoch 14, Loss: 3.320543386042118\n",
      "Training Accuracy: 54.31412887573242%\n",
      "Validation Loss: 2.959648385643959\n",
      "Validation Accuracy: 65.49019622802734%\n",
      "Epoch 15, Loss: 3.145379163324833\n",
      "Training Accuracy: 60.99753952026367%\n",
      "Validation Loss: 2.8438210412859917\n",
      "Validation Accuracy: 69.80392456054688%\n",
      "Epoch 16, Loss: 3.094562441110611\n",
      "Training Accuracy: 60.62901306152344%\n",
      "Validation Loss: 2.768624424934387\n",
      "Validation Accuracy: 69.4117660522461%\n",
      "Epoch 17, Loss: 2.9174949899315834\n",
      "Training Accuracy: 65.86051177978516%\n",
      "Validation Loss: 2.640538278967142\n",
      "Validation Accuracy: 72.45098114013672%\n",
      "Epoch 18, Loss: 3.046232298016548\n",
      "Training Accuracy: 57.01544189453125%\n",
      "Validation Loss: 2.5961710177361965\n",
      "Validation Accuracy: 72.64705657958984%\n",
      "Epoch 19, Loss: 2.8708155676722527\n",
      "Training Accuracy: 63.356204986572266%\n",
      "Validation Loss: 2.4951909817755222\n",
      "Validation Accuracy: 74.90196228027344%\n",
      "Epoch 20, Loss: 2.751564886420965\n",
      "Training Accuracy: 65.3758316040039%\n",
      "Validation Loss: 2.4062081165611744\n",
      "Validation Accuracy: 76.2745132446289%\n",
      "Epoch 21, Loss: 2.9355463460087776\n",
      "Training Accuracy: 57.19096755981445%\n",
      "Validation Loss: 2.4415010884404182\n",
      "Validation Accuracy: 73.03921508789062%\n",
      "Epoch 22, Loss: 2.7979758232831955\n",
      "Training Accuracy: 60.189002990722656%\n",
      "Validation Loss: 2.3509632274508476\n",
      "Validation Accuracy: 74.90196228027344%\n",
      "Epoch 23, Loss: 2.5347820706665516\n",
      "Training Accuracy: 70.17292022705078%\n",
      "Validation Loss: 2.1737721227109432\n",
      "Validation Accuracy: 79.01960754394531%\n",
      "Epoch 24, Loss: 2.791342955082655\n",
      "Training Accuracy: 60.389190673828125%\n",
      "Validation Loss: 2.2236901447176933\n",
      "Validation Accuracy: 76.17646789550781%\n",
      "Epoch 25, Loss: 2.4761902913451195\n",
      "Training Accuracy: 68.35504150390625%\n",
      "Validation Loss: 2.1219823248684406\n",
      "Validation Accuracy: 77.54901885986328%\n",
      "Epoch 26, Loss: 2.4931383542716503\n",
      "Training Accuracy: 65.78189086914062%\n",
      "Validation Loss: 2.1010507568717003\n",
      "Validation Accuracy: 76.86274719238281%\n",
      "Epoch 27, Loss: 2.4728516303002834\n",
      "Training Accuracy: 67.64823913574219%\n",
      "Validation Loss: 1.9800807125866413\n",
      "Validation Accuracy: 80.0%\n",
      "Epoch 28, Loss: 2.469624027609825\n",
      "Training Accuracy: 65.11168670654297%\n",
      "Validation Loss: 1.9990658275783062\n",
      "Validation Accuracy: 78.23529052734375%\n",
      "Epoch 29, Loss: 2.3429273515939713\n",
      "Training Accuracy: 69.111083984375%\n",
      "Validation Loss: 1.9401285834610462\n",
      "Validation Accuracy: 79.50980377197266%\n",
      "Epoch 30, Loss: 2.415338721126318\n",
      "Training Accuracy: 66.12648010253906%\n",
      "Validation Loss: 1.8790743127465248\n",
      "Validation Accuracy: 79.11764526367188%\n",
      "Epoch 31, Loss: 2.5563266165554523\n",
      "Training Accuracy: 62.260501861572266%\n",
      "Validation Loss: 1.945692703127861\n",
      "Validation Accuracy: 77.54901885986328%\n",
      "Epoch 32, Loss: 2.472680192440748\n",
      "Training Accuracy: 63.33112335205078%\n",
      "Validation Loss: 1.799983523786068\n",
      "Validation Accuracy: 78.82353210449219%\n",
      "Epoch 33, Loss: 2.273067630827427\n",
      "Training Accuracy: 68.54996490478516%\n",
      "Validation Loss: 1.7857889644801617\n",
      "Validation Accuracy: 80.19607543945312%\n",
      "Epoch 34, Loss: 2.432446151971817\n",
      "Training Accuracy: 63.27554702758789%\n",
      "Validation Loss: 1.7988582029938698\n",
      "Validation Accuracy: 79.60784149169922%\n",
      "Epoch 35, Loss: 2.2347791381180286\n",
      "Training Accuracy: 68.08733367919922%\n",
      "Validation Loss: 1.7352635003626347\n",
      "Validation Accuracy: 80.68627166748047%\n",
      "Epoch 36, Loss: 2.383362043648958\n",
      "Training Accuracy: 64.16065216064453%\n",
      "Validation Loss: 1.7592897489666939\n",
      "Validation Accuracy: 79.60784149169922%\n",
      "Epoch 37, Loss: 2.4039982706308365\n",
      "Training Accuracy: 62.04847717285156%\n",
      "Validation Loss: 1.8617006316781044\n",
      "Validation Accuracy: 77.05882263183594%\n",
      "Epoch 38, Loss: 2.00151539593935\n",
      "Training Accuracy: 73.68534851074219%\n",
      "Validation Loss: 1.6427898090332747\n",
      "Validation Accuracy: 81.37255096435547%\n",
      "Epoch 39, Loss: 2.2400558814406395\n",
      "Training Accuracy: 66.90094757080078%\n",
      "Validation Loss: 1.6504262313246727\n",
      "Validation Accuracy: 80.49019622802734%\n",
      "Epoch 40, Loss: 2.078623017296195\n",
      "Training Accuracy: 71.81494903564453%\n",
      "Validation Loss: 1.5616919212043285\n",
      "Validation Accuracy: 82.35294342041016%\n",
      "Epoch 41, Loss: 2.1363188344985247\n",
      "Training Accuracy: 68.28008270263672%\n",
      "Validation Loss: 1.6013704277575016\n",
      "Validation Accuracy: 82.1568603515625%\n",
      "Epoch 42, Loss: 2.1347121447324753\n",
      "Training Accuracy: 68.41109466552734%\n",
      "Validation Loss: 1.5016886424273252\n",
      "Validation Accuracy: 83.03921508789062%\n",
      "Epoch 43, Loss: 2.0108069889247417\n",
      "Training Accuracy: 73.12924194335938%\n",
      "Validation Loss: 1.4994058217853308\n",
      "Validation Accuracy: 83.13725280761719%\n",
      "Epoch 44, Loss: 2.2090354412794113\n",
      "Training Accuracy: 65.6869125366211%\n",
      "Validation Loss: 1.5777234118431807\n",
      "Validation Accuracy: 80.68627166748047%\n",
      "Epoch 45, Loss: 2.0780892856419086\n",
      "Training Accuracy: 67.56489562988281%\n",
      "Validation Loss: 1.496297599747777\n",
      "Validation Accuracy: 82.64705657958984%\n",
      "Epoch 46, Loss: 2.0869564451277256\n",
      "Training Accuracy: 69.06021118164062%\n",
      "Validation Loss: 1.4557916335761547\n",
      "Validation Accuracy: 83.23529052734375%\n",
      "Epoch 47, Loss: 2.050213571637869\n",
      "Training Accuracy: 68.79021453857422%\n",
      "Validation Loss: 1.4398563858121634\n",
      "Validation Accuracy: 82.8431396484375%\n",
      "Epoch 48, Loss: 2.028960045427084\n",
      "Training Accuracy: 69.9137954711914%\n",
      "Validation Loss: 1.3997044824063778\n",
      "Validation Accuracy: 84.01960754394531%\n",
      "Epoch 49, Loss: 2.045236414298415\n",
      "Training Accuracy: 68.7531967163086%\n",
      "Validation Loss: 1.405016964301467\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 50, Loss: 2.1307542081922293\n",
      "Training Accuracy: 67.6566390991211%\n",
      "Validation Loss: 1.5211905259639025\n",
      "Validation Accuracy: 80.98039245605469%\n",
      "Epoch 51, Loss: 2.0528620686382055\n",
      "Training Accuracy: 67.32572174072266%\n",
      "Validation Loss: 1.4871193412691355\n",
      "Validation Accuracy: 81.2745132446289%\n",
      "Epoch 52, Loss: 1.9824832677841187\n",
      "Training Accuracy: 70.5926742553711%\n",
      "Validation Loss: 1.4160377848893404\n",
      "Validation Accuracy: 83.23529052734375%\n",
      "Epoch 53, Loss: 2.121136698871851\n",
      "Training Accuracy: 66.05110931396484%\n",
      "Validation Loss: 1.4441938158124685\n",
      "Validation Accuracy: 82.05882263183594%\n",
      "Epoch 54, Loss: 1.8714474197477102\n",
      "Training Accuracy: 71.13434600830078%\n",
      "Validation Loss: 1.3444521725177765\n",
      "Validation Accuracy: 83.4313735961914%\n",
      "Epoch 55, Loss: 2.0195965711027384\n",
      "Training Accuracy: 67.88680267333984%\n",
      "Validation Loss: 1.3355947118252516\n",
      "Validation Accuracy: 83.62744903564453%\n",
      "Epoch 56, Loss: 2.11498755030334\n",
      "Training Accuracy: 65.2232666015625%\n",
      "Validation Loss: 1.3786915224045515\n",
      "Validation Accuracy: 82.54901885986328%\n",
      "Epoch 57, Loss: 1.8297112174332142\n",
      "Training Accuracy: 74.26362609863281%\n",
      "Validation Loss: 1.2786162830889225\n",
      "Validation Accuracy: 84.90196228027344%\n",
      "Epoch 58, Loss: 2.187561947852373\n",
      "Training Accuracy: 62.523597717285156%\n",
      "Validation Loss: 1.3788261245936155\n",
      "Validation Accuracy: 82.45098114013672%\n",
      "Epoch 59, Loss: 2.060433505102992\n",
      "Training Accuracy: 66.16200256347656%\n",
      "Validation Loss: 1.4413717240095139\n",
      "Validation Accuracy: 80.0%\n",
      "Epoch 60, Loss: 2.1409451458603144\n",
      "Training Accuracy: 63.82950973510742%\n",
      "Validation Loss: 1.3384248446673155\n",
      "Validation Accuracy: 82.8431396484375%\n",
      "Epoch 61, Loss: 2.038820141926408\n",
      "Training Accuracy: 68.21726989746094%\n",
      "Validation Loss: 1.3352368604391813\n",
      "Validation Accuracy: 81.86274719238281%\n",
      "Epoch 62, Loss: 2.0275938510894775\n",
      "Training Accuracy: 65.55567932128906%\n",
      "Validation Loss: 1.349208502098918\n",
      "Validation Accuracy: 82.2549057006836%\n",
      "Epoch 63, Loss: 1.8202309608459473\n",
      "Training Accuracy: 72.70844268798828%\n",
      "Validation Loss: 1.2563999481499195\n",
      "Validation Accuracy: 84.21568298339844%\n",
      "Epoch 64, Loss: 2.2143500056117773\n",
      "Training Accuracy: 61.1253547668457%\n",
      "Validation Loss: 1.3888121359050274\n",
      "Validation Accuracy: 81.17646789550781%\n",
      "Epoch 65, Loss: 1.9184465501457453\n",
      "Training Accuracy: 70.04878234863281%\n",
      "Validation Loss: 1.3486859612166882\n",
      "Validation Accuracy: 81.66666412353516%\n",
      "Epoch 66, Loss: 1.7201200723648071\n",
      "Training Accuracy: 74.18280792236328%\n",
      "Validation Loss: 1.1957756131887436\n",
      "Validation Accuracy: 84.70587921142578%\n",
      "Epoch 67, Loss: 1.8579679615795612\n",
      "Training Accuracy: 70.40921783447266%\n",
      "Validation Loss: 1.2258667964488268\n",
      "Validation Accuracy: 84.21568298339844%\n",
      "Epoch 68, Loss: 1.9908414520323277\n",
      "Training Accuracy: 65.11148071289062%\n",
      "Validation Loss: 1.2460573259741068\n",
      "Validation Accuracy: 83.7254867553711%\n",
      "Epoch 69, Loss: 1.9412664864212275\n",
      "Training Accuracy: 69.2421646118164%\n",
      "Validation Loss: 1.2118905130773783\n",
      "Validation Accuracy: 83.4313735961914%\n",
      "Epoch 70, Loss: 1.8791090697050095\n",
      "Training Accuracy: 69.8389892578125%\n",
      "Validation Loss: 1.2123071663081646\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 71, Loss: 1.9020462092012167\n",
      "Training Accuracy: 70.32813262939453%\n",
      "Validation Loss: 1.1695749443024397\n",
      "Validation Accuracy: 84.01960754394531%\n",
      "Epoch 72, Loss: 1.89699337631464\n",
      "Training Accuracy: 68.79693603515625%\n",
      "Validation Loss: 1.2436339613050222\n",
      "Validation Accuracy: 82.7450942993164%\n",
      "Epoch 73, Loss: 1.909430542960763\n",
      "Training Accuracy: 68.61003875732422%\n",
      "Validation Loss: 1.2173890750855207\n",
      "Validation Accuracy: 82.64705657958984%\n",
      "Epoch 74, Loss: 1.79887287132442\n",
      "Training Accuracy: 71.53621673583984%\n",
      "Validation Loss: 1.1655574943870306\n",
      "Validation Accuracy: 84.60784149169922%\n",
      "Epoch 75, Loss: 1.9329295419156551\n",
      "Training Accuracy: 69.40026092529297%\n",
      "Validation Loss: 1.2432542089372873\n",
      "Validation Accuracy: 83.23529052734375%\n",
      "Epoch 76, Loss: 1.8929411377757788\n",
      "Training Accuracy: 68.38394165039062%\n",
      "Validation Loss: 1.1729268282651901\n",
      "Validation Accuracy: 83.92156982421875%\n",
      "Epoch 77, Loss: 2.0759894251823425\n",
      "Training Accuracy: 65.13141632080078%\n",
      "Validation Loss: 1.2211388163268566\n",
      "Validation Accuracy: 83.7254867553711%\n",
      "Epoch 78, Loss: 1.7966054528951645\n",
      "Training Accuracy: 71.99604797363281%\n",
      "Validation Loss: 1.1228647585958242\n",
      "Validation Accuracy: 84.50980377197266%\n",
      "Epoch 79, Loss: 1.795186821371317\n",
      "Training Accuracy: 72.46429443359375%\n",
      "Validation Loss: 1.1143239540979266\n",
      "Validation Accuracy: 85.19607543945312%\n",
      "Epoch 80, Loss: 1.5379876904189587\n",
      "Training Accuracy: 76.92620086669922%\n",
      "Validation Loss: 1.0656535113230348\n",
      "Validation Accuracy: 86.07843017578125%\n",
      "Epoch 81, Loss: 1.6535838544368744\n",
      "Training Accuracy: 74.36652374267578%\n",
      "Validation Loss: 1.1337736491113901\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 82, Loss: 1.8545092083513737\n",
      "Training Accuracy: 70.8947982788086%\n",
      "Validation Loss: 1.1140186870470643\n",
      "Validation Accuracy: 84.60784149169922%\n",
      "Epoch 83, Loss: 1.6395401488989592\n",
      "Training Accuracy: 74.28971862792969%\n",
      "Validation Loss: 1.0597632890567183\n",
      "Validation Accuracy: 85.68627166748047%\n",
      "Epoch 84, Loss: 1.9507624479010701\n",
      "Training Accuracy: 65.50785827636719%\n",
      "Validation Loss: 1.1506726685911417\n",
      "Validation Accuracy: 83.62744903564453%\n",
      "Epoch 85, Loss: 1.9106332901865244\n",
      "Training Accuracy: 66.89033508300781%\n",
      "Validation Loss: 1.151944256387651\n",
      "Validation Accuracy: 84.11764526367188%\n",
      "Epoch 86, Loss: 1.834850948303938\n",
      "Training Accuracy: 70.4032211303711%\n",
      "Validation Loss: 1.1249271668493748\n",
      "Validation Accuracy: 84.31372833251953%\n",
      "Epoch 87, Loss: 1.7452314924448729\n",
      "Training Accuracy: 72.95943450927734%\n",
      "Validation Loss: 1.094753360375762\n",
      "Validation Accuracy: 84.70587921142578%\n",
      "Epoch 88, Loss: 1.7034812737256289\n",
      "Training Accuracy: 73.19031524658203%\n",
      "Validation Loss: 1.0396363316103816\n",
      "Validation Accuracy: 85.98039245605469%\n",
      "Epoch 89, Loss: 1.5547199752181768\n",
      "Training Accuracy: 76.1052017211914%\n",
      "Validation Loss: 1.0432268287986517\n",
      "Validation Accuracy: 85.5882339477539%\n",
      "Epoch 90, Loss: 1.881857244297862\n",
      "Training Accuracy: 68.8339614868164%\n",
      "Validation Loss: 1.105472537688911\n",
      "Validation Accuracy: 84.90196228027344%\n",
      "Epoch 91, Loss: 1.9528616536408663\n",
      "Training Accuracy: 66.34208679199219%\n",
      "Validation Loss: 1.1252851895987988\n",
      "Validation Accuracy: 83.52941131591797%\n",
      "Epoch 92, Loss: 2.0774114076048136\n",
      "Training Accuracy: 60.470027923583984%\n",
      "Validation Loss: 1.1764220148324966\n",
      "Validation Accuracy: 83.33333587646484%\n",
      "Epoch 93, Loss: 1.9029451180249453\n",
      "Training Accuracy: 69.3067855834961%\n",
      "Validation Loss: 1.1242140587419271\n",
      "Validation Accuracy: 83.82353210449219%\n",
      "Epoch 94, Loss: 1.6569809783250093\n",
      "Training Accuracy: 74.71368408203125%\n",
      "Validation Loss: 1.073990523815155\n",
      "Validation Accuracy: 84.50980377197266%\n",
      "Epoch 95, Loss: 1.548116134479642\n",
      "Training Accuracy: 74.90325927734375%\n",
      "Validation Loss: 0.9959507640451193\n",
      "Validation Accuracy: 86.17646789550781%\n",
      "Epoch 96, Loss: 1.8564546965062618\n",
      "Training Accuracy: 70.11811065673828%\n",
      "Validation Loss: 1.1515088509768248\n",
      "Validation Accuracy: 82.8431396484375%\n",
      "Epoch 97, Loss: 1.7661352725699544\n",
      "Training Accuracy: 72.92222595214844%\n",
      "Validation Loss: 1.0608780113980174\n",
      "Validation Accuracy: 84.70587921142578%\n",
      "Epoch 98, Loss: 1.8468018835410476\n",
      "Training Accuracy: 68.05152893066406%\n",
      "Validation Loss: 1.0485593192279339\n",
      "Validation Accuracy: 84.90196228027344%\n",
      "Epoch 99, Loss: 1.9596071746200323\n",
      "Training Accuracy: 66.32050323486328%\n",
      "Validation Loss: 1.1766666732728481\n",
      "Validation Accuracy: 82.54901885986328%\n",
      "Epoch 100, Loss: 1.9166497308760881\n",
      "Training Accuracy: 68.689453125%\n",
      "Validation Loss: 1.1652820855379105\n",
      "Validation Accuracy: 82.54901885986328%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "no_improvement_counter = 0\n",
    "patience = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    for data, target_a, target_b, lam in mixup_loader(train_loader):\n",
    "        data, target_a, target_b = data.to(device), target_a.to(device), target_b.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target_a.size(0)\n",
    "        correct += (lam * predicted.eq(target_a.data).cpu().sum().float() + (1 - lam) * predicted.eq(target_b.data).cpu().sum().float())\n",
    "\n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    print(f\"Training Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    validation_loss = 0\n",
    "    best_validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "    # Print validation accuracy for each epoch\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {validation_loss / len(val_loader)}\")\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_accuracy\n",
    "        no_improvement_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        no_improvement_counter += 1\n",
    "\n",
    "    if no_improvement_counter >= patience:\n",
    "        print(\"Early stopping: No improvement for {} epochs.\".format(patience))\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet152_flowers102_mixup.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2569124533413605\n",
      "Test Accuracy: 79.29744720458984%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model (if not already loaded)\n",
    "model.load_state_dict(torch.load('resnet152_flowers102_mixup.pth'))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        test_correct += predicted.eq(target.data).cpu().sum().float()\n",
    "\n",
    "test_accuracy = 100 * test_correct / total\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys1Pd_f7-Crk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import Flowers102\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ELsdngo-ITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd980064-693c-42e1-f134-d9863067ba2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:10<00:00, 32865879.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 377404.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 9598232.47it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n",
        "])\n",
        "\n",
        "# Download the dataset (training split)\n",
        "train_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='train',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (validation split)\n",
        "val_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='val',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (test split)\n",
        "test_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='test',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uvGsdkC-ajv"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDiTpYS7-L9p",
        "outputId": "22e7f781-a506-442d-9974-79e06c2de0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
        "model.fc = nn.Linear(model.fc.in_features, 102)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi5L1Lmd_dQX",
        "outputId": "96386491-b183-4f46-c3bd-ce87f48a1400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.645186930894852\n",
            "Validation Accuracy: 5.490196078431373%\n",
            "Epoch 2, Loss: 4.407326325774193\n",
            "Validation Accuracy: 20.0%\n",
            "Epoch 3, Loss: 4.1688049882650375\n",
            "Validation Accuracy: 38.627450980392155%\n",
            "Epoch 4, Loss: 3.9370469227433205\n",
            "Validation Accuracy: 51.76470588235294%\n",
            "Epoch 5, Loss: 3.6997362673282623\n",
            "Validation Accuracy: 58.333333333333336%\n",
            "Epoch 6, Loss: 3.4948395490646362\n",
            "Validation Accuracy: 61.27450980392157%\n",
            "Epoch 7, Loss: 3.2905299589037895\n",
            "Validation Accuracy: 64.90196078431373%\n",
            "Epoch 8, Loss: 3.0875002816319466\n",
            "Validation Accuracy: 69.6078431372549%\n",
            "Epoch 9, Loss: 2.8971476703882217\n",
            "Validation Accuracy: 71.86274509803921%\n",
            "Epoch 10, Loss: 2.726731576025486\n",
            "Validation Accuracy: 73.52941176470588%\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print training loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print validation accuracy for each epoch\n",
        "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet50_flowers102.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model (if not already loaded)\n",
        "model.load_state_dict(torch.load('resnet50_flowers102.pth'))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHuQlA4NVoX9",
        "outputId": "29b33e96-477d-4132-817b-24bf977526ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 70.33664010408197%\n",
            "Test Loss: 2.9963252569109664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Be2E2Br8tNJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
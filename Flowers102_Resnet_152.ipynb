{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btnj0twBtnNA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import Flowers102\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmR9uW7etnNE",
        "outputId": "ef5e98ee-ed9e-4e4c-80ed-d83deeee82f1",
        "colab": {
          "referenced_widgets": [
            "dd47138a27784a379bf8537d75813c48",
            "a4c7b4de2e3e434fa9036f01ad22209b",
            "fa245f76ee0a45709603323ac15a7fa1"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd47138a27784a379bf8537d75813c48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/344862509 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4c7b4de2e3e434fa9036f01ad22209b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/502 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa245f76ee0a45709603323ac15a7fa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14989 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n",
        "])\n",
        "\n",
        "# Download the dataset (training split)\n",
        "train_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='train',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (validation split)\n",
        "val_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='val',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (test split)\n",
        "test_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='test',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24bDfXIOtnNG"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qff_AonFtnNG",
        "outputId": "4bcdee40-095e-4609-e390-5bdc5b21018f",
        "colab": {
          "referenced_widgets": [
            "6f1123778d48428287e31ab2aee01270"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/codespace/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f1123778d48428287e31ab2aee01270",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the ResNet-152 model\n",
        "model = models.resnet152(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
        "model.fc = nn.Linear(model.fc.in_features, 102)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdUp-9_9tnNH",
        "outputId": "d6e7c38c-c5c6-43ab-a08a-6c6860e7b289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 4.651366889476776\n",
            "Validation Accuracy: 5.686274509803922%\n",
            "Validation Loss: 4.469683647155762\n",
            "Epoch 2, Loss: 4.387609392404556\n",
            "Validation Accuracy: 20.686274509803923%\n",
            "Validation Loss: 4.2496795654296875\n",
            "Epoch 3, Loss: 4.124314196407795\n",
            "Validation Accuracy: 37.450980392156865%\n",
            "Validation Loss: 4.031835079193115\n",
            "Epoch 4, Loss: 3.8829571902751923\n",
            "Validation Accuracy: 51.76470588235294%\n",
            "Validation Loss: 3.8238792419433594\n",
            "Epoch 5, Loss: 3.635236270725727\n",
            "Validation Accuracy: 59.21568627450981%\n",
            "Validation Loss: 3.6260366439819336\n",
            "Epoch 6, Loss: 3.403437577188015\n",
            "Validation Accuracy: 65.68627450980392%\n",
            "Validation Loss: 3.4359359741210938\n",
            "Epoch 7, Loss: 3.188617281615734\n",
            "Validation Accuracy: 66.96078431372548%\n",
            "Validation Loss: 3.2670066356658936\n",
            "Epoch 8, Loss: 2.977874703705311\n",
            "Validation Accuracy: 71.66666666666667%\n",
            "Validation Loss: 3.0926895141601562\n",
            "Epoch 9, Loss: 2.7843797132372856\n",
            "Validation Accuracy: 73.52941176470588%\n",
            "Validation Loss: 2.9436607360839844\n",
            "Epoch 10, Loss: 2.6049720644950867\n",
            "Validation Accuracy: 73.13725490196079%\n",
            "Validation Loss: 2.7870981693267822\n",
            "Epoch 11, Loss: 2.433276027441025\n",
            "Validation Accuracy: 76.27450980392157%\n",
            "Validation Loss: 2.654486894607544\n",
            "Epoch 12, Loss: 2.2840507179498672\n",
            "Validation Accuracy: 77.25490196078431%\n",
            "Validation Loss: 2.5329694747924805\n",
            "Epoch 13, Loss: 2.130898579955101\n",
            "Validation Accuracy: 78.33333333333333%\n",
            "Validation Loss: 2.427635431289673\n",
            "Epoch 14, Loss: 2.0042862370610237\n",
            "Validation Accuracy: 80.88235294117646%\n",
            "Validation Loss: 2.323552131652832\n",
            "Epoch 15, Loss: 1.8813372701406479\n",
            "Validation Accuracy: 80.29411764705883%\n",
            "Validation Loss: 2.2265617847442627\n",
            "Epoch 16, Loss: 1.759665835648775\n",
            "Validation Accuracy: 81.76470588235294%\n",
            "Validation Loss: 2.125614881515503\n",
            "Epoch 17, Loss: 1.6522386819124222\n",
            "Validation Accuracy: 80.3921568627451%\n",
            "Validation Loss: 2.049736738204956\n",
            "Epoch 18, Loss: 1.566848836839199\n",
            "Validation Accuracy: 82.3529411764706%\n",
            "Validation Loss: 1.9724740982055664\n",
            "Epoch 19, Loss: 1.4848486259579659\n",
            "Validation Accuracy: 82.74509803921569%\n",
            "Validation Loss: 1.9081602096557617\n",
            "Epoch 20, Loss: 1.385831356048584\n",
            "Validation Accuracy: 82.6470588235294%\n",
            "Validation Loss: 1.8434076309204102\n",
            "Epoch 21, Loss: 1.3101749159395695\n",
            "Validation Accuracy: 83.23529411764706%\n",
            "Validation Loss: 1.7754719257354736\n",
            "Epoch 22, Loss: 1.248441917821765\n",
            "Validation Accuracy: 83.62745098039215%\n",
            "Validation Loss: 1.7132270336151123\n",
            "Epoch 23, Loss: 1.1814383286982775\n",
            "Validation Accuracy: 83.43137254901961%\n",
            "Validation Loss: 1.6807711124420166\n",
            "Epoch 24, Loss: 1.1365817617624998\n",
            "Validation Accuracy: 83.52941176470588%\n",
            "Validation Loss: 1.6348421573638916\n",
            "Epoch 25, Loss: 1.065283676609397\n",
            "Validation Accuracy: 83.43137254901961%\n",
            "Validation Loss: 1.5957858562469482\n",
            "Epoch 26, Loss: 1.018265387043357\n",
            "Validation Accuracy: 84.41176470588235%\n",
            "Validation Loss: 1.5522239208221436\n",
            "Epoch 27, Loss: 0.9858626704663038\n",
            "Validation Accuracy: 84.50980392156863%\n",
            "Validation Loss: 1.4999431371688843\n",
            "Epoch 28, Loss: 0.921581307426095\n",
            "Validation Accuracy: 84.11764705882354%\n",
            "Validation Loss: 1.4694511890411377\n",
            "Epoch 29, Loss: 0.9028048571199179\n",
            "Validation Accuracy: 84.01960784313725%\n",
            "Validation Loss: 1.4469751119613647\n",
            "Epoch 30, Loss: 0.8599435240030289\n",
            "Validation Accuracy: 83.62745098039215%\n",
            "Validation Loss: 1.4044548273086548\n",
            "Epoch 31, Loss: 0.8151644058525562\n",
            "Validation Accuracy: 84.41176470588235%\n",
            "Validation Loss: 1.3730522394180298\n",
            "Epoch 32, Loss: 0.7948820386081934\n",
            "Validation Accuracy: 85.0%\n",
            "Validation Loss: 1.3507245779037476\n",
            "Epoch 33, Loss: 0.7747584767639637\n",
            "Validation Accuracy: 84.80392156862744%\n",
            "Validation Loss: 1.340378999710083\n",
            "Epoch 34, Loss: 0.7285141069442034\n",
            "Validation Accuracy: 84.70588235294117%\n",
            "Validation Loss: 1.3098363876342773\n",
            "Epoch 35, Loss: 0.7015436254441738\n",
            "Validation Accuracy: 85.0%\n",
            "Validation Loss: 1.2898075580596924\n",
            "Epoch 36, Loss: 0.6805027201771736\n",
            "Validation Accuracy: 85.09803921568627%\n",
            "Validation Loss: 1.2662841081619263\n",
            "Epoch 37, Loss: 0.6558710299432278\n",
            "Validation Accuracy: 84.6078431372549%\n",
            "Validation Loss: 1.2592800855636597\n",
            "Epoch 38, Loss: 0.6283049117773771\n",
            "Validation Accuracy: 85.98039215686275%\n",
            "Validation Loss: 1.2284101247787476\n",
            "Epoch 39, Loss: 0.6098296623677015\n",
            "Validation Accuracy: 85.19607843137256%\n",
            "Validation Loss: 1.2060751914978027\n",
            "Epoch 40, Loss: 0.5889444360509515\n",
            "Validation Accuracy: 85.88235294117646%\n",
            "Validation Loss: 1.2050001621246338\n",
            "Epoch 41, Loss: 0.5625617392361164\n",
            "Validation Accuracy: 85.68627450980392%\n",
            "Validation Loss: 1.1723151206970215\n",
            "Epoch 42, Loss: 0.5524414349347353\n",
            "Validation Accuracy: 85.3921568627451%\n",
            "Validation Loss: 1.1668387651443481\n",
            "Epoch 43, Loss: 0.536395245231688\n",
            "Validation Accuracy: 85.98039215686275%\n",
            "Validation Loss: 1.149137020111084\n",
            "Epoch 44, Loss: 0.5206675129011273\n",
            "Validation Accuracy: 85.68627450980392%\n",
            "Validation Loss: 1.130612850189209\n",
            "Epoch 45, Loss: 0.5089302882552147\n",
            "Validation Accuracy: 85.98039215686275%\n",
            "Validation Loss: 1.1101562976837158\n",
            "Epoch 46, Loss: 0.4840964712202549\n",
            "Validation Accuracy: 85.68627450980392%\n",
            "Validation Loss: 1.1066259145736694\n",
            "Epoch 47, Loss: 0.47881189174950123\n",
            "Validation Accuracy: 85.58823529411765%\n",
            "Validation Loss: 1.089685320854187\n",
            "Epoch 48, Loss: 0.46797464694827795\n",
            "Validation Accuracy: 86.47058823529412%\n",
            "Validation Loss: 1.0739191770553589\n",
            "Epoch 49, Loss: 0.4499427145346999\n",
            "Validation Accuracy: 85.7843137254902%\n",
            "Validation Loss: 1.0711231231689453\n",
            "Epoch 50, Loss: 0.441164611838758\n",
            "Validation Accuracy: 85.58823529411765%\n",
            "Validation Loss: 1.0628737211227417\n",
            "Epoch 51, Loss: 0.4296444524079561\n",
            "Validation Accuracy: 86.17647058823529%\n",
            "Validation Loss: 1.0487536191940308\n",
            "Epoch 52, Loss: 0.414395640604198\n",
            "Validation Accuracy: 86.27450980392157%\n",
            "Validation Loss: 1.0370444059371948\n",
            "Epoch 53, Loss: 0.4124129759147763\n",
            "Validation Accuracy: 85.98039215686275%\n",
            "Validation Loss: 1.0345653295516968\n",
            "Epoch 54, Loss: 0.39636491797864437\n",
            "Validation Accuracy: 86.27450980392157%\n",
            "Validation Loss: 1.0224628448486328\n",
            "Epoch 55, Loss: 0.38198070507496595\n",
            "Validation Accuracy: 86.17647058823529%\n",
            "Validation Loss: 1.0157588720321655\n",
            "Epoch 56, Loss: 0.3695053867995739\n",
            "Validation Accuracy: 86.37254901960785%\n",
            "Validation Loss: 1.013837218284607\n",
            "Epoch 57, Loss: 0.3722906094044447\n",
            "Validation Accuracy: 86.37254901960785%\n",
            "Validation Loss: 0.9948229789733887\n",
            "Epoch 58, Loss: 0.3573477459140122\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.9879775643348694\n",
            "Epoch 59, Loss: 0.34991889726370573\n",
            "Validation Accuracy: 86.27450980392157%\n",
            "Validation Loss: 0.9739070534706116\n",
            "Epoch 60, Loss: 0.3427479509264231\n",
            "Validation Accuracy: 86.17647058823529%\n",
            "Validation Loss: 0.9734008312225342\n",
            "Epoch 61, Loss: 0.340112516656518\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.9582330584526062\n",
            "Epoch 62, Loss: 0.3322672424837947\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.9672895073890686\n",
            "Epoch 63, Loss: 0.3203500444069505\n",
            "Validation Accuracy: 87.15686274509804%\n",
            "Validation Loss: 0.9582707285881042\n",
            "Epoch 64, Loss: 0.3207445126026869\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.9452815651893616\n",
            "Epoch 65, Loss: 0.3079169290140271\n",
            "Validation Accuracy: 86.07843137254902%\n",
            "Validation Loss: 0.9415342211723328\n",
            "Epoch 66, Loss: 0.29806492617353797\n",
            "Validation Accuracy: 86.76470588235294%\n",
            "Validation Loss: 0.9419607520103455\n",
            "Epoch 67, Loss: 0.294925709720701\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.9265863299369812\n",
            "Epoch 68, Loss: 0.2967417109757662\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.9193024039268494\n",
            "Epoch 69, Loss: 0.2922979276627302\n",
            "Validation Accuracy: 86.96078431372548%\n",
            "Validation Loss: 0.9156894087791443\n",
            "Epoch 70, Loss: 0.280040699057281\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.9034534692764282\n",
            "Epoch 71, Loss: 0.2754240594804287\n",
            "Validation Accuracy: 86.47058823529412%\n",
            "Validation Loss: 0.9071161150932312\n",
            "Epoch 72, Loss: 0.265483062248677\n",
            "Validation Accuracy: 86.27450980392157%\n",
            "Validation Loss: 0.8980934023857117\n",
            "Epoch 73, Loss: 0.2611134257167578\n",
            "Validation Accuracy: 86.47058823529412%\n",
            "Validation Loss: 0.8951221108436584\n",
            "Epoch 74, Loss: 0.2571299821138382\n",
            "Validation Accuracy: 87.15686274509804%\n",
            "Validation Loss: 0.8920679688453674\n",
            "Epoch 75, Loss: 0.2548764059320092\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8836029171943665\n",
            "Epoch 76, Loss: 0.2519280621781945\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8841948509216309\n",
            "Epoch 77, Loss: 0.24181078281253576\n",
            "Validation Accuracy: 86.96078431372548%\n",
            "Validation Loss: 0.8763706684112549\n",
            "Epoch 78, Loss: 0.24638118501752615\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8694025278091431\n",
            "Epoch 79, Loss: 0.23388978699222207\n",
            "Validation Accuracy: 87.25490196078431%\n",
            "Validation Loss: 0.8688404560089111\n",
            "Epoch 80, Loss: 0.23728633532300591\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.8688612580299377\n",
            "Epoch 81, Loss: 0.23094478528946638\n",
            "Validation Accuracy: 86.96078431372548%\n",
            "Validation Loss: 0.8602874875068665\n",
            "Epoch 82, Loss: 0.22997130965813994\n",
            "Validation Accuracy: 87.15686274509804%\n",
            "Validation Loss: 0.8553354740142822\n",
            "Epoch 83, Loss: 0.2246979591436684\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8483453989028931\n",
            "Epoch 84, Loss: 0.22187419701367617\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.8458359241485596\n",
            "Epoch 85, Loss: 0.21540478337556124\n",
            "Validation Accuracy: 87.05882352941177%\n",
            "Validation Loss: 0.8472217917442322\n",
            "Epoch 86, Loss: 0.21250331262126565\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8441416025161743\n",
            "Epoch 87, Loss: 0.2134415004402399\n",
            "Validation Accuracy: 86.86274509803921%\n",
            "Validation Loss: 0.846734344959259\n",
            "Epoch 88, Loss: 0.20995434653013945\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.850502073764801\n",
            "Epoch 89, Loss: 0.200386555865407\n",
            "Validation Accuracy: 86.66666666666667%\n",
            "Validation Loss: 0.8319395780563354\n",
            "Epoch 90, Loss: 0.1997901857830584\n",
            "Validation Accuracy: 86.86274509803921%\n",
            "Validation Loss: 0.8318816423416138\n",
            "Epoch 91, Loss: 0.2042208961211145\n",
            "Validation Accuracy: 86.27450980392157%\n",
            "Validation Loss: 0.8313570618629456\n",
            "Epoch 92, Loss: 0.19805638096295297\n",
            "Validation Accuracy: 86.96078431372548%\n",
            "Validation Loss: 0.81919926404953\n",
            "Epoch 93, Loss: 0.19581722794100642\n",
            "Validation Accuracy: 86.56862745098039%\n",
            "Validation Loss: 0.8201747536659241\n",
            "Epoch 94, Loss: 0.19308533566072583\n",
            "Validation Accuracy: 87.05882352941177%\n",
            "Validation Loss: 0.8109651803970337\n",
            "Epoch 95, Loss: 0.1879809475503862\n",
            "Validation Accuracy: 87.15686274509804%\n",
            "Validation Loss: 0.805871844291687\n",
            "Epoch 96, Loss: 0.18943430995568633\n",
            "Validation Accuracy: 86.47058823529412%\n",
            "Validation Loss: 0.8093597292900085\n",
            "Epoch 97, Loss: 0.1811753048095852\n",
            "Validation Accuracy: 87.05882352941177%\n",
            "Validation Loss: 0.8147107362747192\n",
            "Epoch 98, Loss: 0.18109035957604647\n",
            "Validation Accuracy: 86.86274509803921%\n",
            "Validation Loss: 0.8094571828842163\n",
            "Early stopping at epoch 98 (Best epoch: 95)\n"
          ]
        }
      ],
      "source": [
        "# Initialize early stopping parameters\n",
        "early_stopping_patience = 3 # Number of consecutive epochs without improvement to wait before stopping\n",
        "best_validation_loss = float(\"inf\")\n",
        "best_epoch = 0\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print training loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    validation_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            validation_loss += criterion(outputs, labels)\n",
        "\n",
        "    # Print validation accuracy and loss for each epoch\n",
        "    validation_accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {validation_accuracy}%\")\n",
        "    print(f\"Validation Loss: {validation_loss / len(val_loader)}\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        best_epoch = epoch\n",
        "        no_improvement_count = 0\n",
        "        # Save the model checkpoint\n",
        "        torch.save(model.state_dict(), 'resnet50_flowers102.pth')\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "        if no_improvement_count >= early_stopping_patience:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} (Best epoch: {best_epoch + 1})\")\n",
        "            break  # Stop training\n",
        "\n",
        "# Save the final trained model\n",
        "torch.save(model.state_dict(), 'resnet50_flowers102_final.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UkPvJp8tnNH",
        "outputId": "efb05c17-f414-4958-f80e-b331ad81dca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 83.33062286550658%\n",
            "Test Loss: 0.8888590695056582\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model (if not already loaded)\n",
        "model.load_state_dict(torch.load('resnet50_flowers102.pth'))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID2C1OL8tnNI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ys1Pd_f7-Crk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import Flowers102\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ELsdngo-ITz",
        "outputId": "fd980064-693c-42e1-f134-d9863067ba2a"
      },
      "outputs": [],
      "source": [
        "# Load the Flowers102 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Download the dataset (training split)\n",
        "train_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='train',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (validation split)\n",
        "val_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='val',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")\n",
        "\n",
        "# Download the dataset (test split)\n",
        "test_dataset = Flowers102(\n",
        "    root='./data',  # The root directory where the dataset will be saved\n",
        "    split='test',   # 'train' for the training set, 'test' for the test set\n",
        "    transform=transform,  # Apply the defined transformation\n",
        "    download=True  # Download if not already present\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2uvGsdkC-ajv"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the MixUp function\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a MixUp data loader\n",
        "def mixup_loader(dataloader, alpha=1.0):\n",
        "    for data, target in dataloader:\n",
        "        data, target_a, target_b, lam = mixup_data(data, target, alpha)\n",
        "        yield data, target_a, target_b, lam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDiTpYS7-L9p",
        "outputId": "22e7f781-a506-442d-9974-79e06c2de0a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/codespace/.python/current/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Define the ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "# Modify the output layer to match the number of classes in the dataset (102 for Oxford Flowers)\n",
        "model.fc = nn.Linear(model.fc.in_features, 102)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi5L1Lmd_dQX",
        "outputId": "96386491-b183-4f46-c3bd-ce87f48a1400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 4.6821287125349045\n",
            "Training Accuracy: 1.2290819883346558%\n",
            "Validation Loss: 4.552988916635513\n",
            "Validation Accuracy: 2.941176414489746%\n",
            "Epoch 2, Loss: 4.554063558578491\n",
            "Training Accuracy: 3.552126407623291%\n",
            "Validation Loss: 4.415706738829613\n",
            "Validation Accuracy: 10.29411792755127%\n",
            "Epoch 3, Loss: 4.459620580077171\n",
            "Training Accuracy: 7.412514686584473%\n",
            "Validation Loss: 4.291141033172607\n",
            "Validation Accuracy: 17.54901885986328%\n",
            "Epoch 4, Loss: 4.337478503584862\n",
            "Training Accuracy: 16.120710372924805%\n",
            "Validation Loss: 4.151989296078682\n",
            "Validation Accuracy: 28.52941131591797%\n",
            "Epoch 5, Loss: 4.196594052016735\n",
            "Training Accuracy: 27.983421325683594%\n",
            "Validation Loss: 3.998853988945484\n",
            "Validation Accuracy: 40.0%\n",
            "Epoch 6, Loss: 4.079325683414936\n",
            "Training Accuracy: 34.222660064697266%\n",
            "Validation Loss: 3.8673679307103157\n",
            "Validation Accuracy: 45.882354736328125%\n",
            "Epoch 7, Loss: 4.030183382332325\n",
            "Training Accuracy: 37.20534896850586%\n",
            "Validation Loss: 3.766686365008354\n",
            "Validation Accuracy: 49.313724517822266%\n",
            "Epoch 8, Loss: 3.856865458190441\n",
            "Training Accuracy: 46.748714447021484%\n",
            "Validation Loss: 3.6219556108117104\n",
            "Validation Accuracy: 53.431373596191406%\n",
            "Epoch 9, Loss: 3.8747559189796448\n",
            "Training Accuracy: 40.73688888549805%\n",
            "Validation Loss: 3.536568269133568\n",
            "Validation Accuracy: 55.19607925415039%\n",
            "Epoch 10, Loss: 3.712760843336582\n",
            "Training Accuracy: 50.08384323120117%\n",
            "Validation Loss: 3.419191412627697\n",
            "Validation Accuracy: 57.74509811401367%\n",
            "Epoch 11, Loss: 3.6773953661322594\n",
            "Training Accuracy: 46.88862991333008%\n",
            "Validation Loss: 3.326072432100773\n",
            "Validation Accuracy: 59.509803771972656%\n",
            "Epoch 12, Loss: 3.5480712205171585\n",
            "Training Accuracy: 50.45787811279297%\n",
            "Validation Loss: 3.225085601210594\n",
            "Validation Accuracy: 64.50980377197266%\n",
            "Epoch 13, Loss: 3.47204926609993\n",
            "Training Accuracy: 53.796485900878906%\n",
            "Validation Loss: 3.1188851594924927\n",
            "Validation Accuracy: 65.49019622802734%\n",
            "Epoch 14, Loss: 3.449963577091694\n",
            "Training Accuracy: 52.0384407043457%\n",
            "Validation Loss: 3.0347191467881203\n",
            "Validation Accuracy: 66.76470947265625%\n",
            "Epoch 15, Loss: 3.3594227358698845\n",
            "Training Accuracy: 56.50408935546875%\n",
            "Validation Loss: 2.975100629031658\n",
            "Validation Accuracy: 66.86274719238281%\n",
            "Epoch 16, Loss: 3.2739028334617615\n",
            "Training Accuracy: 56.64307403564453%\n",
            "Validation Loss: 2.8650436624884605\n",
            "Validation Accuracy: 68.52941131591797%\n",
            "Epoch 17, Loss: 3.1946323961019516\n",
            "Training Accuracy: 57.082523345947266%\n",
            "Validation Loss: 2.7979561388492584\n",
            "Validation Accuracy: 71.2745132446289%\n",
            "Epoch 18, Loss: 3.047556459903717\n",
            "Training Accuracy: 62.09601593017578%\n",
            "Validation Loss: 2.7086353823542595\n",
            "Validation Accuracy: 70.39215850830078%\n",
            "Epoch 19, Loss: 2.993891626596451\n",
            "Training Accuracy: 61.73563003540039%\n",
            "Validation Loss: 2.6066428162157536\n",
            "Validation Accuracy: 71.47058868408203%\n",
            "Epoch 20, Loss: 3.0906003788113594\n",
            "Training Accuracy: 56.766727447509766%\n",
            "Validation Loss: 2.5924238190054893\n",
            "Validation Accuracy: 72.35294342041016%\n",
            "Epoch 21, Loss: 2.994565337896347\n",
            "Training Accuracy: 59.30573654174805%\n",
            "Validation Loss: 2.5120411328971386\n",
            "Validation Accuracy: 72.54901885986328%\n",
            "Epoch 22, Loss: 2.7633105739951134\n",
            "Training Accuracy: 66.95191192626953%\n",
            "Validation Loss: 2.377707041800022\n",
            "Validation Accuracy: 75.88235473632812%\n",
            "Epoch 23, Loss: 2.8782817274332047\n",
            "Training Accuracy: 60.50873947143555%\n",
            "Validation Loss: 2.3856435641646385\n",
            "Validation Accuracy: 74.50980377197266%\n",
            "Epoch 24, Loss: 2.8055005855858326\n",
            "Training Accuracy: 62.66142654418945%\n",
            "Validation Loss: 2.3495073057711124\n",
            "Validation Accuracy: 72.64705657958984%\n",
            "Epoch 25, Loss: 2.553100973367691\n",
            "Training Accuracy: 70.50897979736328%\n",
            "Validation Loss: 2.233086723834276\n",
            "Validation Accuracy: 75.78431701660156%\n",
            "Epoch 26, Loss: 2.680082432925701\n",
            "Training Accuracy: 65.5979232788086%\n",
            "Validation Loss: 2.232802599668503\n",
            "Validation Accuracy: 76.07843017578125%\n",
            "Epoch 27, Loss: 2.594241935759783\n",
            "Training Accuracy: 67.4583511352539%\n",
            "Validation Loss: 2.1907545290887356\n",
            "Validation Accuracy: 75.39215850830078%\n",
            "Epoch 28, Loss: 2.761344574391842\n",
            "Training Accuracy: 58.67244338989258%\n",
            "Validation Loss: 2.124176736921072\n",
            "Validation Accuracy: 75.29412078857422%\n",
            "Epoch 29, Loss: 2.5138129703700542\n",
            "Training Accuracy: 68.55541229248047%\n",
            "Validation Loss: 2.093162428587675\n",
            "Validation Accuracy: 76.5686264038086%\n",
            "Epoch 30, Loss: 2.468462146818638\n",
            "Training Accuracy: 68.8144760131836%\n",
            "Validation Loss: 2.021245803683996\n",
            "Validation Accuracy: 77.35294342041016%\n",
            "Epoch 31, Loss: 2.55097783729434\n",
            "Training Accuracy: 64.19821166992188%\n",
            "Validation Loss: 1.9617619402706623\n",
            "Validation Accuracy: 78.13725280761719%\n",
            "Epoch 32, Loss: 2.5999528132379055\n",
            "Training Accuracy: 61.16567611694336%\n",
            "Validation Loss: 1.9439635016024113\n",
            "Validation Accuracy: 78.03921508789062%\n",
            "Epoch 33, Loss: 2.4997144006192684\n",
            "Training Accuracy: 65.05472564697266%\n",
            "Validation Loss: 1.9647484309971333\n",
            "Validation Accuracy: 76.76470947265625%\n",
            "Epoch 34, Loss: 2.410301212221384\n",
            "Training Accuracy: 65.98516082763672%\n",
            "Validation Loss: 1.844163216650486\n",
            "Validation Accuracy: 78.7254867553711%\n",
            "Epoch 35, Loss: 2.4061720743775368\n",
            "Training Accuracy: 65.0478286743164%\n",
            "Validation Loss: 1.8527619242668152\n",
            "Validation Accuracy: 78.62744903564453%\n",
            "Epoch 36, Loss: 2.442733805626631\n",
            "Training Accuracy: 64.51164245605469%\n",
            "Validation Loss: 1.8147662691771984\n",
            "Validation Accuracy: 78.82353210449219%\n",
            "Epoch 37, Loss: 2.4433738626539707\n",
            "Training Accuracy: 63.38312530517578%\n",
            "Validation Loss: 1.8233619816601276\n",
            "Validation Accuracy: 77.64705657958984%\n",
            "Epoch 38, Loss: 2.407078504562378\n",
            "Training Accuracy: 63.065277099609375%\n",
            "Validation Loss: 1.7794379778206348\n",
            "Validation Accuracy: 78.7254867553711%\n",
            "Epoch 39, Loss: 2.4705477990210056\n",
            "Training Accuracy: 60.857303619384766%\n",
            "Validation Loss: 1.7965952828526497\n",
            "Validation Accuracy: 78.23529052734375%\n",
            "Epoch 40, Loss: 2.3481892868876457\n",
            "Training Accuracy: 63.39674758911133%\n",
            "Validation Loss: 1.6657848674803972\n",
            "Validation Accuracy: 79.80392456054688%\n",
            "Epoch 41, Loss: 2.3351046666502953\n",
            "Training Accuracy: 64.2518310546875%\n",
            "Validation Loss: 1.6994632072746754\n",
            "Validation Accuracy: 80.09803771972656%\n",
            "Epoch 42, Loss: 2.210964534431696\n",
            "Training Accuracy: 68.2448501586914%\n",
            "Validation Loss: 1.6623902209103107\n",
            "Validation Accuracy: 79.80392456054688%\n",
            "Epoch 43, Loss: 2.4711300395429134\n",
            "Training Accuracy: 59.934669494628906%\n",
            "Validation Loss: 1.7076266072690487\n",
            "Validation Accuracy: 79.01960754394531%\n",
            "Epoch 44, Loss: 2.1099152378737926\n",
            "Training Accuracy: 70.16136932373047%\n",
            "Validation Loss: 1.5675053391605616\n",
            "Validation Accuracy: 81.37255096435547%\n",
            "Epoch 45, Loss: 2.1107683666050434\n",
            "Training Accuracy: 69.96940612792969%\n",
            "Validation Loss: 1.5761441346257925\n",
            "Validation Accuracy: 80.98039245605469%\n",
            "Epoch 46, Loss: 1.91594348102808\n",
            "Training Accuracy: 74.09849548339844%\n",
            "Validation Loss: 1.5240588244050741\n",
            "Validation Accuracy: 82.64705657958984%\n",
            "Epoch 47, Loss: 2.32537411339581\n",
            "Training Accuracy: 62.82160568237305%\n",
            "Validation Loss: 1.56724994443357\n",
            "Validation Accuracy: 81.07843017578125%\n",
            "Epoch 48, Loss: 2.3354810252785683\n",
            "Training Accuracy: 62.915828704833984%\n",
            "Validation Loss: 1.6367391031235456\n",
            "Validation Accuracy: 78.13725280761719%\n",
            "Epoch 49, Loss: 2.248765531927347\n",
            "Training Accuracy: 64.88490295410156%\n",
            "Validation Loss: 1.5691198483109474\n",
            "Validation Accuracy: 79.90196228027344%\n",
            "Epoch 50, Loss: 2.2373628094792366\n",
            "Training Accuracy: 65.53263854980469%\n",
            "Validation Loss: 1.5199106056243181\n",
            "Validation Accuracy: 80.5882339477539%\n",
            "Epoch 51, Loss: 1.9748798198997974\n",
            "Training Accuracy: 72.58331298828125%\n",
            "Validation Loss: 1.4513060487806797\n",
            "Validation Accuracy: 83.23529052734375%\n",
            "Epoch 52, Loss: 2.0766868889331818\n",
            "Training Accuracy: 68.8314208984375%\n",
            "Validation Loss: 1.4532748311758041\n",
            "Validation Accuracy: 82.1568603515625%\n",
            "Epoch 53, Loss: 1.9208863079547882\n",
            "Training Accuracy: 72.70474243164062%\n",
            "Validation Loss: 1.381631050258875\n",
            "Validation Accuracy: 84.01960754394531%\n",
            "Epoch 54, Loss: 2.0922031570225954\n",
            "Training Accuracy: 67.05142974853516%\n",
            "Validation Loss: 1.4435667991638184\n",
            "Validation Accuracy: 82.2549057006836%\n",
            "Epoch 55, Loss: 2.0423516929149628\n",
            "Training Accuracy: 68.3178482055664%\n",
            "Validation Loss: 1.4709311537444592\n",
            "Validation Accuracy: 81.17646789550781%\n",
            "Epoch 56, Loss: 2.004956064745784\n",
            "Training Accuracy: 70.9841537475586%\n",
            "Validation Loss: 1.432767728343606\n",
            "Validation Accuracy: 81.5686264038086%\n",
            "Epoch 57, Loss: 1.8880830351263285\n",
            "Training Accuracy: 72.71250915527344%\n",
            "Validation Loss: 1.3737174402922392\n",
            "Validation Accuracy: 82.8431396484375%\n",
            "Epoch 58, Loss: 2.1153410989791155\n",
            "Training Accuracy: 64.78033447265625%\n",
            "Validation Loss: 1.3921512104570866\n",
            "Validation Accuracy: 82.35294342041016%\n",
            "Epoch 59, Loss: 1.8790359571576118\n",
            "Training Accuracy: 71.61061096191406%\n",
            "Validation Loss: 1.3396189361810684\n",
            "Validation Accuracy: 82.8431396484375%\n",
            "Epoch 60, Loss: 1.8640753030776978\n",
            "Training Accuracy: 71.49823760986328%\n",
            "Validation Loss: 1.3095925077795982\n",
            "Validation Accuracy: 83.92156982421875%\n",
            "Epoch 61, Loss: 1.9235846418887377\n",
            "Training Accuracy: 70.03030395507812%\n",
            "Validation Loss: 1.3450431246310472\n",
            "Validation Accuracy: 82.35294342041016%\n",
            "Epoch 62, Loss: 2.0917370095849037\n",
            "Training Accuracy: 66.1165771484375%\n",
            "Validation Loss: 1.4125923309475183\n",
            "Validation Accuracy: 81.5686264038086%\n",
            "Epoch 63, Loss: 1.9907496124505997\n",
            "Training Accuracy: 70.09403228759766%\n",
            "Validation Loss: 1.317165318876505\n",
            "Validation Accuracy: 83.23529052734375%\n",
            "Epoch 64, Loss: 2.0909071937203407\n",
            "Training Accuracy: 66.1043472290039%\n",
            "Validation Loss: 1.3351808991283178\n",
            "Validation Accuracy: 81.96078491210938%\n",
            "Epoch 65, Loss: 2.1327213142067194\n",
            "Training Accuracy: 65.38261413574219%\n",
            "Validation Loss: 1.3116114065051079\n",
            "Validation Accuracy: 82.05882263183594%\n",
            "Epoch 66, Loss: 1.7567022871226072\n",
            "Training Accuracy: 75.260986328125%\n",
            "Validation Loss: 1.250436894595623\n",
            "Validation Accuracy: 83.4313735961914%\n",
            "Epoch 67, Loss: 2.026752029545605\n",
            "Training Accuracy: 67.2166748046875%\n",
            "Validation Loss: 1.29258231818676\n",
            "Validation Accuracy: 82.45098114013672%\n",
            "Epoch 68, Loss: 1.792038206011057\n",
            "Training Accuracy: 74.86400604248047%\n",
            "Validation Loss: 1.2381847854703665\n",
            "Validation Accuracy: 83.7254867553711%\n",
            "Epoch 69, Loss: 2.112528033554554\n",
            "Training Accuracy: 64.63471984863281%\n",
            "Validation Loss: 1.3033449407666922\n",
            "Validation Accuracy: 82.1568603515625%\n",
            "Epoch 70, Loss: 1.9215825721621513\n",
            "Training Accuracy: 70.69618225097656%\n",
            "Validation Loss: 1.2290086783468723\n",
            "Validation Accuracy: 83.33333587646484%\n",
            "Epoch 71, Loss: 1.988851984962821\n",
            "Training Accuracy: 67.3792724609375%\n",
            "Validation Loss: 1.2531266938894987\n",
            "Validation Accuracy: 83.92156982421875%\n",
            "Epoch 72, Loss: 1.9018568713217974\n",
            "Training Accuracy: 70.37712860107422%\n",
            "Validation Loss: 1.2454823832958937\n",
            "Validation Accuracy: 84.01960754394531%\n",
            "Epoch 73, Loss: 2.0210857409983873\n",
            "Training Accuracy: 65.52398681640625%\n",
            "Validation Loss: 1.323973573744297\n",
            "Validation Accuracy: 81.07843017578125%\n",
            "Epoch 74, Loss: 1.999102622270584\n",
            "Training Accuracy: 66.5810775756836%\n",
            "Validation Loss: 1.252445885911584\n",
            "Validation Accuracy: 83.03921508789062%\n",
            "Epoch 75, Loss: 1.9177729487419128\n",
            "Training Accuracy: 71.0334701538086%\n",
            "Validation Loss: 1.1911330185830593\n",
            "Validation Accuracy: 83.62744903564453%\n",
            "Epoch 76, Loss: 1.8496697712689638\n",
            "Training Accuracy: 70.98252868652344%\n",
            "Validation Loss: 1.222430270165205\n",
            "Validation Accuracy: 83.92156982421875%\n",
            "Epoch 77, Loss: 2.0373349115252495\n",
            "Training Accuracy: 66.93231201171875%\n",
            "Validation Loss: 1.2496711313724518\n",
            "Validation Accuracy: 83.03921508789062%\n",
            "Epoch 78, Loss: 1.6307021602988243\n",
            "Training Accuracy: 75.8463134765625%\n",
            "Validation Loss: 1.1352490056306124\n",
            "Validation Accuracy: 84.11764526367188%\n",
            "Epoch 79, Loss: 1.9185495134443045\n",
            "Training Accuracy: 67.60610961914062%\n",
            "Validation Loss: 1.1755009833723307\n",
            "Validation Accuracy: 84.11764526367188%\n",
            "Epoch 80, Loss: 1.7745619993656874\n",
            "Training Accuracy: 72.18391418457031%\n",
            "Validation Loss: 1.1728130988776684\n",
            "Validation Accuracy: 84.31372833251953%\n",
            "Epoch 81, Loss: 1.8862804202362895\n",
            "Training Accuracy: 70.52241516113281%\n",
            "Validation Loss: 1.1325240572914481\n",
            "Validation Accuracy: 84.70587921142578%\n",
            "Epoch 82, Loss: 1.9127803416922688\n",
            "Training Accuracy: 68.67474365234375%\n",
            "Validation Loss: 1.1441407650709152\n",
            "Validation Accuracy: 84.11764526367188%\n",
            "Epoch 83, Loss: 1.5746539328247309\n",
            "Training Accuracy: 78.2022476196289%\n",
            "Validation Loss: 1.1012499425560236\n",
            "Validation Accuracy: 85.09803771972656%\n",
            "Epoch 84, Loss: 1.967127088457346\n",
            "Training Accuracy: 67.98014831542969%\n",
            "Validation Loss: 1.2220187205821276\n",
            "Validation Accuracy: 83.33333587646484%\n",
            "Epoch 85, Loss: 1.9578268863260746\n",
            "Training Accuracy: 68.17329406738281%\n",
            "Validation Loss: 1.166933273896575\n",
            "Validation Accuracy: 83.62744903564453%\n",
            "Epoch 86, Loss: 2.083948213607073\n",
            "Training Accuracy: 63.936641693115234%\n",
            "Validation Loss: 1.2183214016258717\n",
            "Validation Accuracy: 82.45098114013672%\n",
            "Epoch 87, Loss: 1.8539106231182814\n",
            "Training Accuracy: 69.3920669555664%\n",
            "Validation Loss: 1.1583900079131126\n",
            "Validation Accuracy: 83.92156982421875%\n",
            "Epoch 88, Loss: 1.7591568231582642\n",
            "Training Accuracy: 72.65152740478516%\n",
            "Validation Loss: 1.1328099463135004\n",
            "Validation Accuracy: 84.50980377197266%\n",
            "Epoch 89, Loss: 1.6982615031301975\n",
            "Training Accuracy: 74.62157440185547%\n",
            "Validation Loss: 1.0787451304495335\n",
            "Validation Accuracy: 85.5882339477539%\n",
            "Epoch 90, Loss: 1.8458711318671703\n",
            "Training Accuracy: 71.13317108154297%\n",
            "Validation Loss: 1.0912666907534003\n",
            "Validation Accuracy: 84.90196228027344%\n",
            "Epoch 91, Loss: 1.7178280372172594\n",
            "Training Accuracy: 73.09864044189453%\n",
            "Validation Loss: 1.109808774664998\n",
            "Validation Accuracy: 85.19607543945312%\n",
            "Epoch 92, Loss: 1.861641677096486\n",
            "Training Accuracy: 70.09011840820312%\n",
            "Validation Loss: 1.09178149048239\n",
            "Validation Accuracy: 84.4117660522461%\n",
            "Epoch 93, Loss: 1.9640253633260727\n",
            "Training Accuracy: 65.4367904663086%\n",
            "Validation Loss: 1.1864193845540285\n",
            "Validation Accuracy: 82.64705657958984%\n",
            "Epoch 94, Loss: 1.6846752585843205\n",
            "Training Accuracy: 73.9443588256836%\n",
            "Validation Loss: 1.1063677426427603\n",
            "Validation Accuracy: 84.90196228027344%\n",
            "Epoch 95, Loss: 2.1184187792241573\n",
            "Training Accuracy: 62.33305740356445%\n",
            "Validation Loss: 1.1525766644626856\n",
            "Validation Accuracy: 83.03921508789062%\n",
            "Epoch 96, Loss: 1.5754513889551163\n",
            "Training Accuracy: 77.62272644042969%\n",
            "Validation Loss: 1.05696034245193\n",
            "Validation Accuracy: 84.60784149169922%\n",
            "Epoch 97, Loss: 1.8109510205686092\n",
            "Training Accuracy: 72.60228729248047%\n",
            "Validation Loss: 1.0921735912561417\n",
            "Validation Accuracy: 84.70587921142578%\n",
            "Epoch 98, Loss: 2.0856971871107817\n",
            "Training Accuracy: 62.22578811645508%\n",
            "Validation Loss: 1.1067271195352077\n",
            "Validation Accuracy: 84.50980377197266%\n",
            "Epoch 99, Loss: 1.7588776722550392\n",
            "Training Accuracy: 71.04591369628906%\n",
            "Validation Loss: 1.0277948202565312\n",
            "Validation Accuracy: 85.29412078857422%\n",
            "Epoch 100, Loss: 1.504854573868215\n",
            "Training Accuracy: 78.64952850341797%\n",
            "Validation Loss: 1.0382924610748887\n",
            "Validation Accuracy: 85.19607543945312%\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_improvement_counter = 0\n",
        "patience = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "    for data, target_a, target_b, lam in mixup_loader(train_loader):\n",
        "        data, target_a, target_b = data.to(device), target_a.to(device), target_b.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target_a.size(0)\n",
        "        correct += (lam * predicted.eq(target_a.data).cpu().sum().float() + (1 - lam) * predicted.eq(target_b.data).cpu().sum().float())\n",
        "\n",
        "    # Print training loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "    print(f\"Training Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    validation_loss = 0\n",
        "    best_validation_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            validation_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.data).cpu().sum().float()\n",
        "\n",
        "    # Print validation accuracy for each epoch\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss: {validation_loss / len(val_loader)}\")\n",
        "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = val_accuracy\n",
        "        no_improvement_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
        "    else:\n",
        "        no_improvement_counter += 1\n",
        "\n",
        "    if no_improvement_counter >= patience:\n",
        "        print(\"Early stopping: No improvement for {} epochs.\".format(patience))\n",
        "        break\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet50_flowers102_mixup.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHuQlA4NVoX9",
        "outputId": "29b33e96-477d-4132-817b-24bf977526ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 1.1083086179328088\n",
            "Test Accuracy: 83.07041931152344%\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model (if not already loaded)\n",
        "model.load_state_dict(torch.load('resnet50_flowers102_mixup.pth'))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        test_correct += predicted.eq(target.data).cpu().sum().float()\n",
        "\n",
        "test_accuracy = 100 * test_correct / total\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
